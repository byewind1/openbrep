"""
gdl-agent Web UI â€” Streamlit interface for architects.

Run: streamlit run ui/app.py
"""

import sys
import re
import os
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import streamlit as st
try:
    from streamlit_ace import st_ace
    _ACE_AVAILABLE = True
except ImportError:
    _ACE_AVAILABLE = False

from gdl_agent.hsf_project import HSFProject, ScriptType, GDLParameter
from gdl_agent.gdl_parser import parse_gdl_source, parse_gdl_file
from gdl_agent.paramlist_builder import build_paramlist_xml, validate_paramlist
from gdl_agent.compiler import MockHSFCompiler, HSFCompiler, CompileResult
from gdl_agent.core import GDLAgent, Status
from gdl_agent.knowledge import KnowledgeBase
from gdl_agent.skills_loader import SkillsLoader


# â”€â”€ Page Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(
    page_title="gdl-agent",
    page_icon="ğŸ—ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â”€â”€ Custom CSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;600&family=Noto+Sans+SC:wght@300;400;600&display=swap');

.stApp { font-family: 'Noto Sans SC', sans-serif; }
code, .stCodeBlock { font-family: 'JetBrains Mono', monospace !important; }

.main-header {
    font-family: 'JetBrains Mono', monospace;
    font-size: 2rem; font-weight: 600;
    background: linear-gradient(135deg, #22d3ee, #34d399);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin-bottom: 0;
}
.sub-header { color: #94a3b8; font-size: 0.9rem; margin-top: -0.5rem; margin-bottom: 2rem; }

.welcome-card {
    background: linear-gradient(135deg, #0f172a, #1e293b);
    border: 1px solid #334155;
    border-radius: 12px;
    padding: 2rem;
    margin: 1rem 0;
}
.step-item {
    display: flex;
    align-items: flex-start;
    gap: 0.75rem;
    margin-bottom: 1rem;
    padding: 0.75rem;
    background: #1e293b;
    border-radius: 8px;
    border-left: 3px solid #22d3ee;
}
.diff-current { border-left: 3px solid #475569; padding-left: 0.5rem; }
.diff-ai      { border-left: 3px solid #f59e0b; padding-left: 0.5rem; }
.diff-badge {
    display: inline-block;
    background: #f59e0b22;
    color: #f59e0b;
    border: 1px solid #f59e0b55;
    border-radius: 4px;
    padding: 2px 8px;
    font-size: 0.78rem;
    font-family: 'JetBrains Mono', monospace;
    margin-bottom: 4px;
}

/* â”€â”€ Column gap tighten â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
/* Streamlit "small" gap still has padding; pull columns closer */
div[data-testid="stHorizontalBlock"] {
    gap: 1rem !important;
}
/* Subtle divider between editor and chat */
div[data-testid="stHorizontalBlock"] > div[data-testid="stColumn"]:last-child {
    border-left: 1px solid #1e293b;
    padding-left: 0.75rem;
}
</style>
""", unsafe_allow_html=True)


# â”€â”€ Session State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if "project" not in st.session_state:
    st.session_state.project = None
if "_import_key_done" not in st.session_state:
    st.session_state._import_key_done = ""   # dedup: skip re-processing same file
if "compile_log" not in st.session_state:
    st.session_state.compile_log = []
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "work_dir" not in st.session_state:
    st.session_state.work_dir = str(Path.home() / "gdl-agent-workspace")
if "agent_running" not in st.session_state:
    st.session_state.agent_running = False
if "pending_diffs" not in st.session_state:
    # AI-proposed changes awaiting user review.
    # Keys: "scripts/3d.gdl" etc. + "paramlist.xml" for parameters
    st.session_state.pending_diffs = {}
if "pending_ai_label" not in st.session_state:
    # Human-readable label shown in the confirmation banner
    st.session_state.pending_ai_label = ""
if "pending_gsm_name" not in st.session_state:
    st.session_state.pending_gsm_name = ""
if "confirm_clear" not in st.session_state:
    st.session_state.confirm_clear = False
if "editor_version" not in st.session_state:
    # Increment on import/clear to force text_area widget recreation (avoids stale Streamlit cache)
    st.session_state.editor_version = 0
if "model_api_keys" not in st.session_state:
    # Per-model API Key storage â€” pre-fill from config.toml provider_keys
    st.session_state.model_api_keys = {}


# â”€â”€ Load config.toml defaults â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_config_defaults = {}
_provider_keys: dict = {}   # {provider: api_key}

try:
    from gdl_agent.config import GDLAgentConfig
    import sys as _sys, os as _os
    # Load raw TOML to get provider_keys nested table
    if _sys.version_info >= (3, 11):
        import tomllib as _tomllib
    else:
        import tomli as _tomllib   # type: ignore

    _toml_path = _os.path.join(_os.path.dirname(__file__), "..", "config.toml")
    if _os.path.exists(_toml_path):
        with open(_toml_path, "rb") as _f:
            _raw = _tomllib.load(_f)
        _provider_keys = _raw.get("llm", {}).get("provider_keys", {})

    _config = GDLAgentConfig.load()
    _config_defaults = {
        "llm_model": _config.llm.model,
        "compiler_path": _config.compiler.path or "",
    }
except Exception:
    pass


def _key_for_model(model: str) -> str:
    """Pick the right API Key from provider_keys based on model name."""
    m = model.lower()
    if "glm" in m:
        return _provider_keys.get("zhipu", "")
    elif "deepseek" in m and "ollama" not in m:
        return _provider_keys.get("deepseek", "")
    elif "claude" in m:
        return _provider_keys.get("anthropic", "")
    elif "gpt" in m or "o3" in m or "o1" in m:
        return _provider_keys.get("openai", "")
    elif "gemini" in m:
        return _provider_keys.get("google", "")
    return ""

# â”€â”€ Sidebar Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with st.sidebar:
    st.markdown('<p class="main-header">gdl-agent</p>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">v0.5.0 Â· HSF-native Â· AI-powered</p>', unsafe_allow_html=True)
    st.divider()

    st.subheader("ğŸ“ å·¥ä½œç›®å½•")
    work_dir = st.text_input("Work Directory", value=st.session_state.work_dir, label_visibility="collapsed")
    st.session_state.work_dir = work_dir

    st.divider()
    st.subheader("ğŸ”§ ç¼–è¯‘å™¨ / Compiler")

    compiler_mode = st.radio(
        "ç¼–è¯‘æ¨¡å¼",
        ["Mock (æ— éœ€ ArchiCAD)", "LP_XMLConverter (çœŸå®ç¼–è¯‘)"],
        index=1 if _config_defaults.get("compiler_path") else 0,
    )

    converter_path = ""
    if compiler_mode.startswith("LP"):
        converter_path = st.text_input(
            "LP_XMLConverter è·¯å¾„",
            value=_config_defaults.get("compiler_path", ""),
            placeholder="/Applications/GRAPHISOFT/ArchiCAD 28/LP_XMLConverter.app/Contents/MacOS/LP_XMLConverter",
        )

    st.divider()
    st.subheader("ğŸ§  AI æ¨¡å‹ / LLM")

    model_options = [
        # â”€â”€ Anthropic Claude â”€â”€
        "claude-haiku-4-5-20251001",
        "claude-sonnet-4-5-20250929",
        "claude-opus-4-5-20250918",
        "claude-opus-4-6",
        # â”€â”€ æ™ºè°± GLM (Z.ai) â”€â”€
        "glm-4.7",
        "glm-4.7-flash",
        "glm-4-plus",
        "glm-4-flash",
        # â”€â”€ OpenAI â”€â”€
        "gpt-4o",
        "gpt-4o-mini",
        "o3-mini",
        # â”€â”€ DeepSeek â”€â”€
        "deepseek-chat",
        "deepseek-reasoner",
        # â”€â”€ Google Gemini â”€â”€
        "gemini/gemini-2.5-flash",
        "gemini/gemini-2.5-pro",
        # â”€â”€ Ollama æœ¬åœ° â”€â”€
        "ollama/qwen2.5:14b",
        "ollama/qwen3:8b",
        "ollama/deepseek-coder-v2:16b",
    ]

    default_model = _config_defaults.get("llm_model", "glm-4.7")
    default_index = model_options.index(default_model) if default_model in model_options else 4

    model_name = st.selectbox("æ¨¡å‹ / Model", model_options, index=default_index)

    # Load or initialize API Key for this specific model
    if model_name not in st.session_state.model_api_keys:
        # Auto-fill from config.toml provider_keys
        st.session_state.model_api_keys[model_name] = _key_for_model(model_name)

    api_key = st.text_input(
        "API Key",
        value=st.session_state.model_api_keys.get(model_name, ""),
        type="password",
        help="Ollama æœ¬åœ°æ¨¡å¼ä¸éœ€è¦ Key"
    )

    # Auto-save API Key if user manually edited it
    if api_key != st.session_state.model_api_keys.get(model_name, ""):
        st.session_state.model_api_keys[model_name] = api_key

    if "claude" in model_name:
        st.caption("ğŸ”‘ [è·å– Claude API Key â†’](https://console.anthropic.com/settings/keys)")
        st.caption("âš ï¸ API Key éœ€å•ç‹¬å……å€¼ï¼Œä¸ Claude Pro è®¢é˜…é¢åº¦æ— å…³")
    elif "glm" in model_name:
        st.caption("ğŸ”‘ [è·å–æ™ºè°± API Key â†’](https://bigmodel.cn/usercenter/apikeys)")
    elif "gpt" in model_name or "o3" in model_name:
        st.caption("ğŸ”‘ [è·å– OpenAI API Key â†’](https://platform.openai.com/api-keys)")
    elif "deepseek" in model_name and "ollama" not in model_name:
        st.caption("ğŸ”‘ [è·å– DeepSeek API Key â†’](https://platform.deepseek.com/api_keys)")
    elif "gemini" in model_name:
        st.caption("ğŸ”‘ [è·å– Gemini API Key â†’](https://aistudio.google.com/apikey)")
    elif "ollama" in model_name:
        st.caption("ğŸ–¥ï¸ æœ¬åœ°è¿è¡Œï¼Œæ— éœ€ Keyã€‚ç¡®ä¿ Ollama å·²å¯åŠ¨ã€‚")

    # API Base URL â€” only needed for OpenAI-compatible custom endpoints
    # zai/ (GLM), deepseek/, anthropic/ are native LiteLLM providers, no api_base needed
    def _get_default_api_base(model: str) -> str:
        m = model.lower()
        if "ollama" in m:
            return "http://localhost:11434"
        # GLM uses zai/ native provider â€” no api_base
        # DeepSeek uses deepseek/ native provider â€” no api_base
        return ""

    default_api_base = _get_default_api_base(model_name)
    api_base = ""
    if default_api_base:
        api_base = st.text_input("API Base URL", value=default_api_base)

    max_retries = st.slider("æœ€å¤§é‡è¯•æ¬¡æ•°", 1, 10, 5)

    st.divider()

    # Project info + quick reset
    if st.session_state.project:
        proj = st.session_state.project
        st.subheader(f"ğŸ“¦ {proj.name}")
        st.caption(f"å‚æ•°: {len(proj.parameters)} | è„šæœ¬: {len(proj.scripts)}")
        if st.button("ğŸ—‘ï¸ æ¸…é™¤é¡¹ç›®", use_container_width=True):
            _keep_work_dir  = st.session_state.work_dir
            _keep_api_keys  = st.session_state.model_api_keys
            _keep_chat      = st.session_state.chat_history   # preserve chat
            st.session_state.project          = None
            st.session_state.compile_log      = []
            st.session_state.pending_diffs    = {}
            st.session_state.pending_ai_label = ""
            st.session_state.pending_gsm_name = ""
            st.session_state.agent_running    = False
            st.session_state._import_key_done = ""
            st.session_state.editor_version  += 1
            st.session_state.work_dir         = _keep_work_dir
            st.session_state.model_api_keys   = _keep_api_keys
            st.session_state.chat_history     = _keep_chat
            st.rerun()


# â”€â”€ Helper Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import json as _json, datetime as _datetime

def _save_feedback(msg_idx: int, rating: str, content: str) -> None:
    """Save ğŸ‘/ğŸ‘ feedback to work_dir/feedback.jsonl (local only, not sent anywhere)."""
    try:
        feedback_path = Path(st.session_state.work_dir) / "feedback.jsonl"
        feedback_path.parent.mkdir(parents=True, exist_ok=True)
        record = {
            "ts": _datetime.datetime.now().isoformat(),
            "rating": rating,           # "positive" | "negative"
            "msg_idx": msg_idx,
            "preview": content[:300],
        }
        with open(feedback_path, "a", encoding="utf-8") as _f:
            _f.write(_json.dumps(record, ensure_ascii=False) + "\n")
    except Exception:
        pass   # never let feedback save break the UI


# â”€â”€ Fullscreen editor dialog (Streamlit â‰¥ 1.36) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_HAS_DIALOG = hasattr(st, "dialog")

if _HAS_DIALOG:
    @st.dialog("â›¶ å…¨å±ç¼–è¾‘", width="large")
    def _fullscreen_editor_dialog(stype: "ScriptType", fpath: str, label: str) -> None:
        st.caption(f"**{label}** è„šæœ¬ Â· å…¨å±æ¨¡å¼ â€” ç¼–è¾‘å®Œæˆç‚¹ã€Œâœ… åº”ç”¨ã€")
        code = (st.session_state.project or HSFProject.create_new("untitled")).get_script(stype) or ""
        if _ACE_AVAILABLE:
            _raw_fs = st_ace(
                value=code, language="fortran", theme="monokai",
                height=580, font_size=14, tab_size=2,
                show_gutter=True, show_print_margin=False,
                key=f"fs_ace_{fpath}",
            )
            new_code = _raw_fs if _raw_fs is not None else code
        else:
            new_code = st.text_area("code", value=code, height=580,
                                    label_visibility="collapsed", key=f"fs_ta_{fpath}") or ""
        c1, c2 = st.columns([2, 6])
        with c1:
            if st.button("âœ… åº”ç”¨", type="primary", use_container_width=True):
                if st.session_state.project:
                    st.session_state.project.set_script(stype, new_code)
                    st.session_state.editor_version += 1
                st.rerun()
        with c2:
            if st.button("âŒ å–æ¶ˆ", use_container_width=True):
                st.rerun()
else:
    def _fullscreen_editor_dialog(stype, fpath, label):  # type: ignore[misc]
        st.info("å…¨å±ç¼–è¾‘éœ€è¦ Streamlit â‰¥ 1.36ï¼Œè¯·å‡çº§ï¼š`pip install -U streamlit`")


def get_compiler():
    if compiler_mode.startswith("Mock"):
        return MockHSFCompiler()
    return HSFCompiler(converter_path or None)

def get_llm():
    from gdl_agent.config import LLMConfig
    from gdl_agent.llm import LLMAdapter
    config = LLMConfig(
        model=model_name,
        api_key=api_key,
        api_base=api_base,
        temperature=0.2,
        max_tokens=4096,
    )
    return LLMAdapter(config)

def load_knowledge(task_type: str = "all"):
    # Always load from project knowledge dir first (contains pro ccgdl_dev_doc)
    project_kb = Path(__file__).parent.parent / "knowledge"
    kb = KnowledgeBase(str(project_kb))
    kb.load()

    # Merge user's custom knowledge from work_dir (if different & exists)
    user_kb_dir = Path(st.session_state.work_dir) / "knowledge"
    if user_kb_dir.exists() and user_kb_dir != project_kb:
        user_kb = KnowledgeBase(str(user_kb_dir))
        user_kb.load()
        kb._docs.update(user_kb._docs)   # user custom overrides project

    return kb.get_by_task_type(task_type)

def load_skills():
    # Always load from project skills dir first
    project_sk = Path(__file__).parent.parent / "skills"
    sl = SkillsLoader(str(project_sk))
    sl.load()

    # Merge user's custom skills from work_dir
    user_sk_dir = Path(st.session_state.work_dir) / "skills"
    if user_sk_dir.exists() and user_sk_dir != project_sk:
        user_sl = SkillsLoader(str(user_sk_dir))
        user_sl.load()
        sl._skills.update(user_sl._skills)   # user custom overrides project

    return sl

def _versioned_gsm_path(proj_name: str, work_dir: str) -> str:
    """
    Return next available versioned GSM path.
    MyShelf_v1.gsm â†’ MyShelf_v2.gsm â†’ ...
    Preserves all previous compilations.
    """
    out_dir = Path(work_dir) / "output"
    out_dir.mkdir(parents=True, exist_ok=True)
    v = 1
    while (out_dir / f"{proj_name}_v{v}.gsm").exists():
        v += 1
    return str(out_dir / f"{proj_name}_v{v}.gsm")


# â”€â”€ Object Name Extraction (dictionary + regex, no LLM) â”€â”€

_CN_TO_NAME = {
    # å®¶å…·
    "ä¹¦æ¶": "Bookshelf", "ä¹¦æŸœ": "Bookcase", "æŸœå­": "Cabinet",
    "è¡£æŸœ": "Wardrobe", "æ©±æŸœ": "Kitchen Cabinet", "å‚¨ç‰©æŸœ": "StorageUnit",
    "æ¡Œå­": "Table", "æ¡Œ": "Table", "ä¹¦æ¡Œ": "Desk", "é¤æ¡Œ": "DiningTable",
    "æ¤…å­": "Chair", "æ¤…": "Chair", "æ²™å‘": "Sofa", "åºŠ": "Bed",
    "èŒ¶å‡ ": "CoffeeTable", "ç”µè§†æŸœ": "TVStand", "é‹æŸœ": "ShoeRack",
    # å»ºç­‘æ„ä»¶
    "çª—": "Window", "çª—æ¡†": "WindowFrame", "çª—æˆ·": "Window", "ç™¾å¶çª—": "Louver",
    "é—¨": "Door", "é—¨æ¡†": "DoorFrame", "æ¨æ‹‰é—¨": "SlidingDoor", "æ—‹è½¬é—¨": "RevolvingDoor",
    "å¢™": "Wall", "å¢™æ¿": "WallPanel", "éš”å¢™": "Partition", "å¹•å¢™": "CurtainWall",
    "æ¥¼æ¢¯": "Staircase", "å°é˜¶": "StairStep", "æ‰¶æ‰‹": "Handrail", "æ æ†": "Railing",
    "æŸ±": "Column", "æŸ±å­": "Column", "æ¢": "Beam", "æ¿": "Slab",
    "å±‹é¡¶": "Roof", "å¤©èŠ±": "Ceiling", "åœ°æ¿": "Floor",
    # è®¾å¤‡
    "ç¯": "Light", "ç¯å…·": "LightFixture", "ç®¡é“": "Pipe", "é£ç®¡": "Duct",
    "å¼€å…³": "Switch", "æ’åº§": "Outlet", "ç©ºè°ƒ": "AirConditioner",
    # æ™¯è§‚
    "èŠ±ç›†": "Planter", "æ ‘": "Tree", "å›´æ ": "Fence", "é•¿å‡³": "Bench",
}

def _extract_object_name(text: str) -> str:
    """
    Extract GDL object name from user input.
    Priority: explicit English name > Chinese keyword dict > fallback.
    Zero LLM calls â€” instant and 100% reliable.
    """
    # 1. Check for explicit English name: "named MyShelf", "å« MyShelf"
    for pat in [
        r'named?\s+([A-Za-z][A-Za-z0-9]{2,30})',
        r'called\s+([A-Za-z][A-Za-z0-9]{2,30})',
        r'åä¸º\s*([A-Za-z][A-Za-z0-9]{2,30})',
        r'å«\s*([A-Za-z][A-Za-z0-9]{2,30})',
    ]:
        m = re.search(pat, text, re.IGNORECASE)
        if m:
            return m.group(1)

    # 2. Chinese keyword â†’ English CamelCase (longest match first)
    for cn, en in sorted(_CN_TO_NAME.items(), key=lambda x: len(x[0]), reverse=True):
        if cn in text:
            print(f"[name] '{cn}' â†’ {en}")
            return en

    # 3. Pick first CamelCase English word in text (skip short junk like UI, AI, GDL)
    for word in re.findall(r'[A-Z][a-z]{2,}[A-Za-z0-9]*', text):
        if word not in {"The", "For", "And", "Not", "But", "With"}:
            return word

    return "MyObject"


# â”€â”€ Welcome / Onboarding Panel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def show_welcome():
    st.markdown("""
<div class="welcome-card">
<h2 style="color:#22d3ee; margin-top:0; font-family:'JetBrains Mono';">æ¬¢è¿ä½¿ç”¨ gdl-agent ğŸ—ï¸</h2>
<p style="color:#94a3b8;">ç”¨è‡ªç„¶è¯­è¨€é©±åŠ¨ ArchiCAD GDL å¯¹è±¡çš„åˆ›å»ºä¸ç¼–è¯‘ã€‚æ— éœ€äº†è§£ GDL è¯­æ³•ï¼Œç›´æ¥æè¿°éœ€æ±‚å³å¯ã€‚</p>
</div>
""", unsafe_allow_html=True)

    st.markdown("#### ä¸‰æ­¥å¿«é€Ÿå¼€å§‹")

    st.info("**â‘  é…ç½® API Key**  \nåœ¨å·¦ä¾§è¾¹æ é€‰æ‹© AI æ¨¡å‹ï¼Œå¡«å…¥å¯¹åº” API Keyã€‚å…è´¹çš„æ™ºè°± GLM å¯ç›´æ¥ä½¿ç”¨ã€‚")
    st.info("**â‘¡ å¼€å§‹å¯¹è¯**  \nåœ¨åº•éƒ¨è¾“å…¥æ¡†æè¿°ä½ æƒ³åˆ›å»ºçš„ GDL å¯¹è±¡ï¼Œä¾‹å¦‚ï¼š  \nã€Œåˆ›å»ºä¸€ä¸ªå®½ 600mmã€æ·± 400mm çš„ä¹¦æ¶ï¼Œå¸¦ iShelves å‚æ•°æ§åˆ¶å±‚æ•°ã€")
    st.info("**â‘¢ ç¼–è¯‘è¾“å‡º**  \nAI ç”Ÿæˆä»£ç åè‡ªåŠ¨è§¦å‘ç¼–è¯‘ã€‚çœŸå®ç¼–è¯‘éœ€åœ¨ä¾§è¾¹æ é…ç½® LP_XMLConverter è·¯å¾„ã€‚Mock æ¨¡å¼å¯éªŒè¯ç»“æ„ï¼Œæ— éœ€å®‰è£… ArchiCADã€‚")

    st.divider()

    st.markdown("#### æˆ–è€…ï¼šå¯¼å…¥å·²æœ‰æ–‡ä»¶")
    uploaded_file = st.file_uploader(
        "æ‹–å…¥ .gdl / .txt / .gsm æ–‡ä»¶",
        type=["gdl", "txt", "gsm"],
        help=".gdl / .txt ç›´æ¥è§£æè„šæœ¬ï¼›.gsm éœ€ä¾§è¾¹æ åˆ‡æ¢ä¸º LP æ¨¡å¼",
        key="welcome_upload",
    )
    if uploaded_file:
        ok, msg = _handle_unified_import(uploaded_file)
        if not ok:
            st.error(msg)
        else:
            st.rerun()

    st.divider()
    st.caption("ğŸ’¡ æç¤ºï¼šç¬¬ä¸€æ¡æ¶ˆæ¯æ— éœ€åˆ›å»ºé¡¹ç›®ï¼Œç›´æ¥æè¿°éœ€æ±‚ï¼ŒAI ä¼šè‡ªåŠ¨åˆå§‹åŒ–ã€‚")


# â”€â”€ Intent Classification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_GDL_KEYWORDS = [
    # åŠ¨ä½œ
    "åˆ›å»º", "ç”Ÿæˆ", "åˆ¶ä½œ", "åšä¸€ä¸ª", "å»ºä¸€ä¸ª", "å†™ä¸€ä¸ª", "å†™ä¸ª", "å†™ä¸€",
    "åšä¸ª", "å»ºä¸ª", "æ¥ä¸ª", "æ•´ä¸ª", "å‡ºä¸€ä¸ª", "å‡ºä¸ª",
    "ä¿®æ”¹", "æ›´æ–°", "æ·»åŠ ", "åˆ é™¤", "è°ƒæ•´", "ä¼˜åŒ–", "é‡å†™", "è¡¥å……",
    # å»ºç­‘/å®¶å…·å¯¹è±¡ï¼ˆä¸­æ–‡ï¼‰
    "ä¹¦æ¶", "æŸœå­", "è¡£æŸœ", "æ©±æŸœ", "å‚¨ç‰©æŸœ", "é‹æŸœ", "ç”µè§†æŸœ",
    "æ¡Œå­", "æ¡Œ", "æ¤…å­", "æ¤…", "æ²™å‘", "åºŠ", "èŒ¶å‡ ", "æŸœ",
    "çª—", "é—¨", "å¢™", "æ¥¼æ¢¯", "æŸ±", "æ¢", "æ¿", "æ‰¶æ‰‹", "æ æ†",
    "å±‹é¡¶", "å¤©èŠ±", "åœ°æ¿", "ç¯", "ç®¡é“",
    # æŠ€æœ¯è¯
    "å‚æ•°", "parameter", "script", "gdl", "gsm", "hsf",
    "compile", "ç¼–è¯‘", "build", "create", "make", "add",
    "3d", "2d", "prism", "block", "sphere", "prism_", "body",
    "project2", "rect2", "poly2",
]

# Pure chat patterns â€” greeting / meta questions only
_CHAT_ONLY_PATTERNS = [
    r"^(ä½ å¥½|hello|hi|hey|å—¨|å“ˆå–½)[!ï¼ã€‚\s]*$",
    r"^(è°¢è°¢|æ„Ÿè°¢|thanks)[!ï¼ã€‚\s]*$",
    r"^ä½ (æ˜¯è°|èƒ½åšä»€ä¹ˆ|æœ‰ä»€ä¹ˆåŠŸèƒ½)",
    r"^(æ€ä¹ˆ|å¦‚ä½•|ä»€ä¹ˆæ˜¯).*(gdl|archicad|hsf|æ„ä»¶)",
]

def _is_gdl_intent(text: str) -> bool:
    t = text.lower()
    return any(kw in t for kw in _GDL_KEYWORDS)

def _is_pure_chat(text: str) -> bool:
    return any(re.search(p, text.strip(), re.IGNORECASE) for p in _CHAT_ONLY_PATTERNS)

def classify_and_extract(text: str, llm, project_loaded: bool = False) -> tuple:
    """
    Returns: (intent, obj_name)
    When project is already loaded, default to GDL for anything ambiguous.
    """
    obj_name = _extract_object_name(text)

    # Pure greetings / meta questions always â†’ CHAT regardless of project state
    if _is_pure_chat(text):
        return ("CHAT", obj_name)

    # Keyword fast-path
    if _is_gdl_intent(text):
        return ("GDL", obj_name)

    # Project loaded: assume user wants to edit â€” treat ambiguous as GDL
    if project_loaded:
        print(f"[classify] project loaded â†’ default GDL for: '{text[:40]}'")
        return ("GDL", obj_name)

    # No project, ambiguous â†’ ask LLM (one word)
    try:
        resp = llm.generate([
            {
                "role": "system",
                "content": (
                    "ä½ æ˜¯æ„å›¾åˆ†ç±»å™¨ã€‚åˆ¤æ–­ç”¨æˆ·æ˜¯å¦æƒ³åˆ›å»ºæˆ–ä¿®æ”¹ ArchiCAD GDL æ„ä»¶ã€‚\n"
                    "åªå›å¤ä¸€ä¸ªè¯ï¼šGDL æˆ– CHAT\n"
                    "GDL = è¦åˆ›å»º/ä¿®æ”¹/ç¼–è¯‘æ„ä»¶\n"
                    "CHAT = é—²èŠ/æ‰“æ‹›å‘¼/é—®ç”¨æ³•"
                ),
            },
            {"role": "user", "content": text},
        ], max_tokens=10, temperature=0.1)

        raw = resp.content.strip().upper()
        print(f"[classify] LLM intent: '{raw}'")
        return ("GDL" if "GDL" in raw else "CHAT", obj_name)

    except Exception as e:
        print(f"[classify] exception: {e}")
        return ("CHAT", obj_name)


def chat_respond(user_input: str, history: list, llm) -> str:
    """Simple conversational response. Never outputs GDL code â€” that goes to the editor."""
    system_msg = {
        "role": "system",
        "content": (
            "ä½ æ˜¯ gdl-agent çš„å†…ç½®åŠ©æ‰‹ï¼Œä¸“æ³¨äº ArchiCAD GDL å¯¹è±¡ç¼–è¾‘å™¨çš„ä½¿ç”¨æŒ‡å¼•ã€‚\n"
            "ã€é‡è¦çº¦æŸã€‘ç»å¯¹ç¦æ­¢åœ¨å›å¤ä¸­è¾“å‡ºä»»ä½• GDL ä»£ç ã€ä»£ç å—æˆ–è„šæœ¬ç‰‡æ®µã€‚"
            "å¦‚æœç”¨æˆ·æƒ³åˆ›å»ºæˆ–ä¿®æ”¹ GDL å¯¹è±¡ï¼Œå‘Šè¯‰ä»–ã€Œç›´æ¥åœ¨åº•éƒ¨è¾“å…¥æ¡†æè¿°éœ€æ±‚ï¼ŒAI ä¼šè‡ªåŠ¨ç”Ÿæˆå¹¶å¡«å…¥ç¼–è¾‘å™¨ã€ã€‚\n"
            "ä¸è¦æåŠ ArchiCAD å†…éƒ¨æ“ä½œï¼ˆå¦‚æ‰“å¼€ GDL å¯¹è±¡ç¼–è¾‘å™¨ï¼‰ï¼Œå› ä¸ºæœ¬å·¥å…·å°±æ˜¯ä½“å¤–çš„ GDL IDEã€‚\n"
            "å›å¤ç®€æ´ï¼Œä½¿ç”¨ä¸­æ–‡ï¼Œä¸“ä¸šæœ¯è¯­ä¿ç•™è‹±æ–‡ï¼ˆGDLã€HSFã€GSMã€paramlist ç­‰ï¼‰ã€‚"
        ),
    }
    messages = [system_msg]
    # Include recent history for context (last 6 messages)
    for msg in history[-6:]:
        messages.append({"role": msg["role"], "content": msg["content"]})
    messages.append({"role": "user", "content": user_input})

    try:
        resp = llm.generate(messages)
        return resp.content
    except Exception as e:
        return f"âŒ {str(e)}"


# â”€â”€ Script Map (module-level, shared by agent + editor) â”€â”€â”€
_SCRIPT_MAP = [
    (ScriptType.SCRIPT_3D, "scripts/3d.gdl",  "3D"),
    (ScriptType.SCRIPT_2D, "scripts/2d.gdl",  "2D"),
    (ScriptType.MASTER,    "scripts/1d.gdl",  "Master"),
    (ScriptType.PARAM,     "scripts/vl.gdl",  "Param"),
    (ScriptType.UI,        "scripts/ui.gdl",  "UI"),
    (ScriptType.PROPERTIES,"scripts/pr.gdl",  "Properties"),
]

# â”€â”€ Run Agent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Keywords that signal debug/analysis intent â†’ inject all scripts + allow plain-text reply
_DEBUG_KEYWORDS = {
    "debug", "fix", "error", "bug", "wrong", "issue", "broken", "fail", "crash",
    "é—®é¢˜", "é”™è¯¯", "è°ƒè¯•", "æ£€æŸ¥", "åˆ†æ", "ä¸ºä»€ä¹ˆ", "å¸®æˆ‘çœ‹", "çœ‹çœ‹", "å‡ºé”™",
    "ä¸å¯¹", "ä¸è¡Œ", "å“ªé‡Œ", "åŸå› ", "è§£é‡Š", "explain", "why", "what", "how",
    "review", "çœ‹ä¸€ä¸‹", "çœ‹ä¸‹", "å‘Šè¯‰æˆ‘", "è¿™æ®µ", "è¿™ä¸ªè„šæœ¬",
}

def _is_debug_intent(text: str) -> bool:
    t = text.lower()
    return any(kw in t for kw in _DEBUG_KEYWORDS)


def run_agent_generate(user_input: str, proj: HSFProject, status_col, gsm_name: str = None) -> str:
    """
    Unified chat+generate entry point.
    - Debug/analysis intent  â†’ all scripts in context, LLM may reply with plain text OR [FILE:] fixes
    - Generation intent      â†’ affected scripts only, LLM writes [FILE:] code blocks
    Always applies [FILE:] code blocks if present; shows plain-text analysis in chat if not.
    """
    status_ph = status_col.empty()
    debug_mode = _is_debug_intent(user_input)

    def on_event(event_type, data):
        if event_type == "analyze":
            scripts = data.get("affected_scripts", [])
            mode_tag = " [å…¨è„šæœ¬]" if debug_mode else ""
            status_ph.info(f"ğŸ” åˆ†æä¸­{mode_tag}... è„šæœ¬: {', '.join(scripts)}")
        elif event_type == "attempt":
            status_ph.info("ğŸ§  è°ƒç”¨ AI...")
        elif event_type == "llm_response":
            status_ph.info(f"âœï¸ æ”¶åˆ° {data['length']} å­—ç¬¦ï¼Œè§£æä¸­...")

    try:
        llm = get_llm()
        knowledge = load_knowledge()
        skills_text = load_skills().get_for_task(user_input)

        # Pass recent chat history for multi-turn context (last 6 messages, skip heavy code blocks)
        recent_history = [
            m for m in st.session_state.chat_history[-8:]
            if m["role"] in ("user", "assistant")
        ]

        agent = GDLAgent(llm=llm, compiler=get_compiler(), on_event=on_event)
        changes, plain_text = agent.generate_only(
            instruction=user_input, project=proj,
            knowledge=knowledge, skills=skills_text,
            include_all_scripts=debug_mode,
            history=recent_history,
        )
        status_ph.empty()

        reply_parts = []

        # Plain-text analysis from LLM (debug/explanation)
        if plain_text:
            reply_parts.append(plain_text)

        # Code changes â€” strip fences, apply or queue for confirmation
        if changes:
            cleaned = {k: _strip_md_fences(v) for k, v in changes.items()}

            script_names = ", ".join(
                p.replace("scripts/", "").replace(".gdl", "").upper()
                for p in cleaned if p.startswith("scripts/")
            )
            has_params = "paramlist.xml" in cleaned
            param_count_preview = len(_parse_paramlist_text(cleaned.get("paramlist.xml", "")))

            code_blocks = []
            for fpath, code in cleaned.items():
                lbl = fpath.replace("scripts/", "").replace(".gdl", "").upper()
                code_blocks.append(f"**{lbl}**\n```gdl\n{code}\n```")

            if debug_mode:
                # Debug / analysis: queue for user confirmation, don't overwrite immediately
                st.session_state.pending_diffs = cleaned
                label_parts = []
                if script_names:
                    label_parts.append(f"è„šæœ¬ [{script_names}]")
                if has_params:
                    label_parts.append(f"{param_count_preview} ä¸ªå‚æ•°")
                st.session_state.pending_ai_label = " + ".join(label_parts)
                notice = (
                    f"ğŸ¤– **AI å·²ç”Ÿæˆæ–°å†…å®¹** â€” {' + '.join(label_parts)}\n\n"
                    "ğŸ‘† ç¼–è¾‘å™¨é¡¶éƒ¨å¯ç¡®è®¤å†™å…¥æˆ–å¿½ç•¥ã€‚"
                )
                reply_parts.append(notice + "\n\n" + "\n\n".join(code_blocks))
            else:
                # Creation / edit mode: auto-apply immediately
                sc, pc = _apply_scripts_to_project(proj, cleaned)
                st.session_state.editor_version += 1
                if gsm_name:
                    st.session_state.pending_gsm_name = gsm_name
                parts_applied = []
                if script_names:
                    parts_applied.append(f"è„šæœ¬ [{script_names}]")
                if pc:
                    parts_applied.append(f"{pc} ä¸ªå‚æ•°")
                applied_label = " + ".join(parts_applied) if parts_applied else "å†…å®¹"
                reply_parts.append(
                    f"âœï¸ **å·²å†™å…¥ {applied_label}** â€” å¯ç›´æ¥ã€ŒğŸ”§ ç¼–è¯‘ã€\n\n"
                    + "\n\n".join(code_blocks)
                )

        if reply_parts:
            return "\n\n---\n\n".join(reply_parts)

        return "ğŸ¤” AI æœªè¿”å›ä»£ç æˆ–åˆ†æï¼Œè¯·æ¢ä¸€ç§æè¿°æ–¹å¼ã€‚"

    except Exception as e:
        status_ph.empty()
        return f"âŒ **é”™è¯¯**: {str(e)}"


def _parse_paramlist_text(text: str) -> list:
    """
    Parse 'Type Name = Value ! Description' lines â†’ list[GDLParameter].
    Handles LLM output from [FILE: paramlist.xml] sections.
    """
    import re as _re
    _VALID_TYPES = {
        "Length", "Angle", "RealNum", "Integer", "Boolean",
        "String", "PenColor", "FillPattern", "LineType", "Material",
    }
    params = []
    for line in text.splitlines():
        line = line.strip()
        if not line or line.startswith("!") or line.startswith("#"):
            continue
        # Format: Type Name = Value  [! description]
        m = _re.match(r'(\w+)\s+(\w+)\s*=\s*(.+?)(?:\s*!\s*(.*))?$', line)
        if m:
            ptype, pname, pval, pdesc = m.groups()
            if ptype in _VALID_TYPES:
                params.append(GDLParameter(
                    pname, ptype, (pdesc or "").strip(), pval.strip().strip('"'),
                ))
    return params


def _apply_scripts_to_project(proj: HSFProject, script_map: dict) -> tuple[int, int]:
    """
    Apply {fpath: content} dict to project.
    Handles scripts/3d.gdl etc. + paramlist.xml.
    Returns (script_count, param_count) for notification.
    """
    sc = 0
    for stype, fpath, _label in _SCRIPT_MAP:
        if fpath in script_map:
            proj.set_script(stype, script_map[fpath])
            sc += 1
    pc = 0
    if "paramlist.xml" in script_map:
        new_params = _parse_paramlist_text(script_map["paramlist.xml"])
        if new_params:
            proj.parameters = new_params
            pc = len(new_params)
    return sc, pc


def do_compile(proj: HSFProject, gsm_name: str, instruction: str = "") -> tuple:
    """
    Compile current project state â†’ versioned GSM.
    Returns (success: bool, message: str).
    """
    try:
        output_gsm = _versioned_gsm_path(gsm_name or proj.name, st.session_state.work_dir)
        hsf_dir = proj.save_to_disk()
        result = get_compiler().hsf2libpart(str(hsf_dir), output_gsm)
        mock_tag = " [Mock]" if compiler_mode.startswith("Mock") else ""

        if result.success:
            st.session_state.compile_log.append({
                "project": proj.name, "instruction": instruction,
                "success": True, "attempts": 1, "message": "Success",
            })
            msg = f"âœ… **ç¼–è¯‘æˆåŠŸ{mock_tag}**\n\nğŸ“¦ `{output_gsm}`"
            if compiler_mode.startswith("Mock"):
                msg += "\n\nâš ï¸ Mock æ¨¡å¼ä¸ç”ŸæˆçœŸå® .gsmï¼Œåˆ‡æ¢ LP_XMLConverter è¿›è¡ŒçœŸå®ç¼–è¯‘ã€‚"
            return (True, msg)
        else:
            st.session_state.compile_log.append({
                "project": proj.name, "instruction": instruction,
                "success": False, "attempts": 1, "message": result.stderr,
            })
            return (False, f"âŒ **ç¼–è¯‘å¤±è´¥**\n\n```\n{result.stderr[:500]}\n```")
    except Exception as e:
        return (False, f"âŒ **é”™è¯¯**: {str(e)}")


def import_gsm(gsm_bytes: bytes, filename: str) -> tuple:
    """
    Decompile GSM â†’ HSF â†’ HSFProject via LP_XMLConverter libpart2hsf.
    Returns (project | None, message).
    """
    import tempfile, shutil
    compiler = get_compiler()

    # Guard: must have a real compiler
    if isinstance(compiler, MockHSFCompiler):
        return (None, "âŒ GSM å¯¼å…¥éœ€è¦ LP_XMLConverterï¼ŒMock æ¨¡å¼ä¸æ”¯æŒã€‚è¯·åœ¨ä¾§è¾¹æ é€‰æ‹© LP æ¨¡å¼å¹¶æŒ‡å®šè·¯å¾„ã€‚")

    # Diagnostic: report which binary will be used
    bin_path = compiler.converter_path or "(æœªæ£€æµ‹åˆ°)"
    if not compiler.is_available:
        return (
            None,
            f"âŒ LP_XMLConverter æœªæ‰¾åˆ°\n\n"
            f"æ£€æµ‹è·¯å¾„: `{bin_path}`\n\n"
            f"macOS æ­£ç¡®è·¯å¾„ç¤ºä¾‹:\n"
            f"`/Applications/GRAPHISOFT/ArchiCAD 28/LP_XMLConverter.app/Contents/MacOS/LP_XMLConverter`\n\n"
            f"è¯·åœ¨ä¾§è¾¹æ æ‰‹åŠ¨å¡«å†™æ­£ç¡®è·¯å¾„ã€‚"
        )

    tmp = Path(tempfile.mkdtemp())
    gsm_path = tmp / filename
    gsm_path.write_bytes(gsm_bytes)
    hsf_out = tmp / "hsf_out"
    hsf_out.mkdir()

    result = compiler.libpart2hsf(str(gsm_path), str(hsf_out))

    if not result.success:
        # Show full diagnostics so user can debug
        diag = result.stderr or result.stdout or "(æ— è¾“å‡º)"
        shutil.rmtree(tmp, ignore_errors=True)
        return (
            None,
            f"âŒ GSM è§£åŒ…å¤±è´¥ (exit={result.exit_code})\n\n"
            f"**Binary**: `{bin_path}`\n\n"
            f"**è¾“å‡º**:\n```\n{diag[:800]}\n```"
        )

    try:
        # Locate true HSF root â€” LP_XMLConverter output layout varies by AC version:
        #   AC 27/28 (standard): hsf_out/<LIBPARTNAME>/libpartdata.xml + scripts/
        #   AC 29 (flat):        hsf_out/libpartdata.xml + scripts/  (no named subdir)
        def _find_hsf_root(base: Path) -> Path:
            # 1. base itself has libpartdata.xml â†’ it IS the HSF root
            if (base / "libpartdata.xml").exists():
                return base
            # 2. base itself has a scripts/ subdir â†’ treat base as root
            if (base / "scripts").is_dir():
                return base
            # 3. one named subdir with libpartdata.xml â†’ standard layout
            for d in sorted(base.iterdir()):
                if d.is_dir() and (d / "libpartdata.xml").exists():
                    return d
            # 4. one named subdir with scripts/ â†’ standard layout without metadata
            for d in sorted(base.iterdir()):
                if d.is_dir() and (d / "scripts").is_dir():
                    return d
            # 5. last resort: first subdir (or base itself)
            subdirs = [d for d in base.iterdir() if d.is_dir()]
            return subdirs[0] if subdirs else base

        hsf_dir = _find_hsf_root(hsf_out)

        if not hsf_dir.exists():
            contents = list(hsf_out.iterdir())
            shutil.rmtree(tmp, ignore_errors=True)
            return (
                None,
                f"âŒ æ— æ³•å®šä½ HSF æ ¹ç›®å½•\n\n"
                f"hsf_out å†…å®¹: `{[str(c.name) for c in contents]}`\n\n"
                f"stdout: {result.stdout[:300]}\nstderr: {result.stderr[:300]}"
            )

        # Snapshot directory tree before rmtree wipes it
        hsf_files = sorted(str(p.relative_to(hsf_dir)) for p in hsf_dir.rglob("*") if p.is_file())

        proj = HSFProject.load_from_disk(str(hsf_dir))
        # AC29 flat layout: hsf_dir == hsf_out â†’ name is "hsf_out", use GSM stem instead
        gsm_stem = Path(filename).stem
        if proj.name in ("hsf_out", "scripts", ""):
            proj.name = gsm_stem
        proj.work_dir = Path(st.session_state.work_dir)
        proj.root = proj.work_dir / proj.name

        scripts_found = [s.value for s in proj.scripts]
        diag = (
            f"\n\n**HSF æ–‡ä»¶åˆ—è¡¨**: `{hsf_files}`"
            f"\n**å·²è¯†åˆ«è„šæœ¬**: `{scripts_found}`"
        )
        return (proj, f"âœ… å·²å¯¼å…¥ `{proj.name}` â€” {len(proj.parameters)} å‚æ•°ï¼Œ{len(proj.scripts)} è„šæœ¬{diag}")
    except Exception as e:
        return (None, f"âŒ HSF è§£æå¤±è´¥: {e}")
    finally:
        shutil.rmtree(tmp, ignore_errors=True)


def _handle_unified_import(uploaded_file) -> tuple[bool, str]:
    """
    Single entry point for importing any GDL-related file.
    - .gsm           â†’ LP_XMLConverter decompile â†’ HSFProject
    - .gdl / .txt    â†’ parse_gdl_source text parse â†’ HSFProject
    Updates session_state.project, pending_gsm_name, editor_version.
    Returns (success, message).
    """
    fname = uploaded_file.name
    ext   = Path(fname).suffix.lower()

    if ext == ".gsm":
        with st.spinner("è§£åŒ… GSM..."):
            proj, msg = import_gsm(uploaded_file.read(), fname)
        if not proj:
            return (False, msg)
    else:
        # .gdl / .txt â€” plain text
        try:
            content = uploaded_file.read().decode("utf-8", errors="replace")
            proj = parse_gdl_source(content, Path(fname).stem)
        except Exception as e:
            return (False, f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        msg = f"âœ… å·²å¯¼å…¥ GDL `{proj.name}` â€” {len(proj.parameters)} å‚æ•°ï¼Œ{len(proj.scripts)} è„šæœ¬"

    proj.work_dir = Path(st.session_state.work_dir)
    proj.root = proj.work_dir / proj.name
    st.session_state.project = proj
    st.session_state.pending_diffs = {}
    st.session_state.pending_gsm_name = proj.name
    st.session_state.editor_version += 1
    st.session_state.chat_history.append({"role": "assistant", "content": msg})
    return (True, msg)


def _strip_md_fences(code: str) -> str:
    """Remove markdown code fences (```gdl / ```) that AI sometimes leaks into scripts."""
    import re as _re
    # Remove opening fence (```gdl, ```GDL, ```)
    code = _re.sub(r'^```[a-zA-Z]*\s*\n?', '', code.strip(), flags=_re.MULTILINE)
    # Remove closing fence
    code = _re.sub(r'\n?```\s*$', '', code.strip(), flags=_re.MULTILINE)
    return code.strip()


def _extract_gdl_from_chat() -> dict:
    """
    Scan chat history for fenced code blocks containing GDL/paramlist.
    Returns {script_path_or_"paramlist.xml": content}.
    Multiple blocks â†’ last block wins per type.

    Classification priority:
      1. paramlist.xml  â€” lines look like 'Type Name = Value'
      2. scripts/2d.gdl â€” has PROJECT2 / RECT2 / POLY2
      3. scripts/vl.gdl â€” has VALUES or LOCK keyword (GDL param script)
      4. scripts/1d.gdl â€” has GLOB_ variable
      5. scripts/ui.gdl â€” has UI_CURRENT or DEFINE STYLE
      6. scripts/3d.gdl â€” default
    """
    import re as _re
    collected: dict[str, str] = {}
    # Match ``` (optional lang tag) ... ``` â€” handles empty lang, gdl, GDL, xml, etc.
    code_block_pat = _re.compile(r"```[a-zA-Z]*[ \t]*\n(.*?)```", _re.DOTALL)
    # Paramlist line: starts with a valid GDL type word followed by identifier = value
    _PARAM_TYPE_RE = _re.compile(
        r'^\s*(Length|Angle|RealNum|Integer|Boolean|String|PenColor|FillPattern|LineType|Material)'
        r'\s+\w+\s*=', _re.IGNORECASE | _re.MULTILINE
    )

    for msg in st.session_state.get("chat_history", []):
        if msg.get("role") != "assistant":
            continue
        content = msg.get("content", "")
        for m in code_block_pat.finditer(content):
            block = m.group(1).strip()
            if not block:
                continue
            block_up = block.upper()

            # 1. Paramlist: â‰¥2 lines matching 'Type Var = value'
            if len(_PARAM_TYPE_RE.findall(block)) >= 2:
                path = "paramlist.xml"
            # 2. 2D projection
            elif _re.search(r'\bPROJECT2\b|\bRECT2\b|\bPOLY2\b', block_up):
                path = "scripts/2d.gdl"
            # 3. Param/Vl script
            elif _re.search(r'\bVALUES\b|\bLOCK\b', block_up) and not _re.search(r'\bBLOCK\b', block_up):
                path = "scripts/vl.gdl"
            # 4. Master script
            elif _re.search(r'\bGLOB_\w+\b', block_up):
                path = "scripts/1d.gdl"
            # 5. UI script
            elif _re.search(r'\bUI_CURRENT\b|\bDEFINE\s+STYLE\b', block_up):
                path = "scripts/ui.gdl"
            else:
                path = "scripts/3d.gdl"
            collected[path] = block

    return collected


def check_gdl_script(content: str, script_type: str = "") -> list:
    """
    Basic GDL syntax check. Returns list of warning strings (empty = OK).
    Checks: IF/ENDIF, FOR/NEXT, ADD/DEL balance, END in 3D, PROJECT2 in 2D.
    """
    import re as _re
    issues = []
    if not content.strip():
        if script_type == "2d":
            issues.append("âš ï¸ 2D è„šæœ¬ä¸ºç©ºï¼Œå¿…é¡»è‡³å°‘åŒ…å« PROJECT2 3, 270, 2")
        return issues

    lines = content.splitlines()

    # IF/ENDIF balance (only multi-line IF: IF ... THEN at end of line)
    if_multi = sum(
        1 for l in lines
        if _re.search(r'\bIF\b', l, _re.I)
        and _re.search(r'\bTHEN\s*$', l.strip(), _re.I)
    )
    endif_count = sum(1 for l in lines if _re.match(r'\s*ENDIF\b', l, _re.I))
    if if_multi != endif_count:
        issues.append(f"âš ï¸ IF/ENDIF ä¸åŒ¹é…ï¼š{if_multi} ä¸ªå¤šè¡Œ IFï¼Œ{endif_count} ä¸ª ENDIF")

    # FOR/NEXT balance
    for_count = sum(1 for l in lines if _re.match(r'\s*FOR\b', l, _re.I))
    next_count = sum(1 for l in lines if _re.match(r'\s*NEXT\b', l, _re.I))
    if for_count != next_count:
        issues.append(f"âš ï¸ FOR/NEXT ä¸åŒ¹é…ï¼š{for_count} ä¸ª FORï¼Œ{next_count} ä¸ª NEXT")

    # ADD/DEL balance â€” ADDX/ADDY/ADDZ are single-axis variants, count equally
    add_count = sum(1 for l in lines if _re.match(r'\s*ADD(X|Y|Z)?\b', l, _re.I))
    del_count = sum(1 for l in lines if _re.match(r'\s*DEL\b', l, _re.I))
    if add_count != del_count:
        issues.append(f"âš ï¸ ADD/DEL ä¸åŒ¹é…ï¼š{add_count} ä¸ª ADD/ADDX/ADDY/ADDZï¼Œ{del_count} ä¸ª DEL")

    # Markdown fence leak â€” common when AI generates code in chat
    if any(l.strip().startswith("```") for l in lines):
        issues.append("âš ï¸ è„šæœ¬å«æœ‰ ``` æ ‡è®° â€” AI æ ¼å¼åŒ–æ®‹ç•™ï¼Œè¯·åˆ é™¤æ‰€æœ‰åå¼•å·è¡Œ")

    # 3D: END / subroutine RETURN check
    if script_type == "3d":
        # Detect subroutine labels:  "SubName":
        sub_label_pat = _re.compile(r'^\s*"[^"]+"\s*:')
        has_subs = any(sub_label_pat.match(l) for l in lines)

        if has_subs:
            # Main body = lines before first subroutine label
            main_body = []
            for l in lines:
                if sub_label_pat.match(l):
                    break
                main_body.append(l)
            last_main = next((l.strip() for l in reversed(main_body) if l.strip()), "")
            if not _re.match(r'^END\s*$', last_main, _re.I):
                issues.append("âš ï¸ 3D ä¸»ä½“éƒ¨åˆ†ï¼ˆç¬¬ä¸€ä¸ªå­ç¨‹åºä¹‹å‰ï¼‰æœ€åä¸€è¡Œå¿…é¡»æ˜¯ END")

            # Each subroutine should end with RETURN (not END)
            current_sub = None
            sub_lines: list[str] = []
            for l in lines:
                if sub_label_pat.match(l):
                    if current_sub and sub_lines:
                        last_sub = next((s.strip() for s in reversed(sub_lines) if s.strip()), "")
                        if not _re.match(r'^RETURN\s*$', last_sub, _re.I):
                            issues.append(f"âš ï¸ å­ç¨‹åº {current_sub} æœ«å°¾åº”ä¸º RETURNï¼Œä¸æ˜¯ END")
                    current_sub = l.strip()
                    sub_lines = []
                else:
                    sub_lines.append(l)
            # Check last subroutine
            if current_sub and sub_lines:
                last_sub = next((s.strip() for s in reversed(sub_lines) if s.strip()), "")
                if not _re.match(r'^RETURN\s*$', last_sub, _re.I):
                    issues.append(f"âš ï¸ å­ç¨‹åº {current_sub} æœ«å°¾åº”ä¸º RETURN")
        else:
            last_non_empty = next((l.strip() for l in reversed(lines) if l.strip()), "")
            if not _re.match(r'^END\s*$', last_non_empty, _re.I):
                issues.append("âš ï¸ 3D è„šæœ¬æœ€åä¸€è¡Œå¿…é¡»æ˜¯ END")

    # 2D: must have projection
    if script_type == "2d":
        has_proj = any(
            _re.search(r'\bPROJECT2\b|\bRECT2\b|\bPOLY2\b', l, _re.I)
            for l in lines
        )
        if not has_proj:
            issues.append("âš ï¸ 2D è„šæœ¬ç¼ºå°‘å¹³é¢æŠ•å½±è¯­å¥ï¼ˆPROJECT2 / RECT2ï¼‰")

    # _var æœªåœ¨æœ¬è„šæœ¬å†…èµ‹å€¼çš„ä¸­é—´å˜é‡ï¼ˆå¯èƒ½éœ€åœ¨ Master è„šæœ¬ä¸­å®šä¹‰ï¼‰
    assigned = set(_re.findall(r'\b(_[A-Za-z]\w*)\s*=', content))
    used     = set(_re.findall(r'\b(_[A-Za-z]\w*)\b', content))
    undefined = used - assigned
    if undefined:
        issues.append(
            f"â„¹ï¸ å˜é‡ {', '.join(sorted(undefined))} åœ¨æœ¬è„šæœ¬æœªèµ‹å€¼ â€” "
            "è‹¥å·²åœ¨ Master è„šæœ¬ä¸­å®šä¹‰å¯å¿½ç•¥ï¼Œå¦åˆ™ä¼šå¯¼è‡´ ArchiCAD è¿è¡Œæ—¶ä¸æ˜¾ç¤º"
        )

    if not issues:
        issues = ["âœ… æ£€æŸ¥é€šè¿‡"]
    return issues


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Main Layout: Left Chat | Right Editor
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Layout: Editor (left/main) | AI Chat (right sidebar)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

col_editor, col_chat = st.columns([3, 2], gap="small")


# â”€â”€ Left: Code Editor (always visible) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_SCRIPT_HELP = {
    "scripts/3d.gdl": (
        "**3D è„šæœ¬** â€” ä¸‰ç»´å‡ ä½•ä½“å®šä¹‰ï¼ŒArchiCAD 3D çª—å£ä¸­æ˜¾ç¤ºçš„å®ä½“ã€‚\n\n"
        "- ä½¿ç”¨ `PRISM_`ã€`BLOCK`ã€`SPHERE`ã€`CONE`ã€`REVOLVE` ç­‰å‘½ä»¤å»ºæ¨¡\n"
        "- `ADD` / `DEL` ç®¡ç†åæ ‡ç³»å˜æ¢ï¼Œå¿…é¡»æˆå¯¹å‡ºç°\n"
        "- `FOR` / `NEXT` å¾ªç¯ç”¨äºé‡å¤æ„ä»¶ï¼ˆå¦‚æ ¼æ …ã€å±‚æ¿ï¼‰\n"
        "- **æœ€åä¸€è¡Œå¿…é¡»æ˜¯ `END`**ï¼Œå¦åˆ™ç¼–è¯‘å¤±è´¥"
    ),
    "scripts/2d.gdl": (
        "**2D è„šæœ¬** â€” å¹³é¢å›¾ç¬¦å·ï¼ŒArchiCAD æ¥¼å±‚å¹³é¢å›¾ä¸­æ˜¾ç¤ºçš„çº¿æ¡ã€‚\n\n"
        "- **å¿…é¡»åŒ…å«** `PROJECT2 3, 270, 2`ï¼ˆæœ€ç®€æŠ•å½±ï¼‰æˆ–è‡ªå®šä¹‰ 2D çº¿æ¡\n"
        "- ä¸å†™æˆ–ç•™ç©ºä¼šå¯¼è‡´å¹³é¢å›¾ä¸­å¯¹è±¡ä¸å¯è§"
    ),
    "scripts/1d.gdl": (
        "**Master è„šæœ¬** â€” ä¸»æ§è„šæœ¬ï¼Œæ‰€æœ‰è„šæœ¬æ‰§è¡Œå‰æœ€å…ˆè¿è¡Œã€‚\n\n"
        "- å…¨å±€å˜é‡åˆå§‹åŒ–ã€å‚æ•°è”åŠ¨é€»è¾‘\n"
        "- ç®€å•å¯¹è±¡é€šå¸¸ä¸éœ€è¦æ­¤è„šæœ¬"
    ),
    "scripts/vl.gdl": (
        "**Param è„šæœ¬** â€” å‚æ•°éªŒè¯è„šæœ¬ï¼Œå‚æ•°å€¼å˜åŒ–æ—¶è§¦å‘ã€‚\n\n"
        "- å‚æ•°èŒƒå›´çº¦æŸã€æ´¾ç”Ÿå‚æ•°è®¡ç®—\n"
        "- ç®€å•å¯¹è±¡é€šå¸¸ä¸éœ€è¦æ­¤è„šæœ¬"
    ),
    "scripts/ui.gdl": (
        "**UI è„šæœ¬** â€” è‡ªå®šä¹‰å‚æ•°ç•Œé¢ï¼ŒArchiCAD å¯¹è±¡è®¾ç½®å¯¹è¯æ¡†æ§ä»¶å¸ƒå±€ã€‚\n\n"
        "- ä¸å†™åˆ™ ArchiCAD è‡ªåŠ¨ç”Ÿæˆé»˜è®¤å‚æ•°åˆ—è¡¨ç•Œé¢"
    ),
    "scripts/pr.gdl": (
        "**Properties è„šæœ¬** â€” BIM å±æ€§è¾“å‡ºï¼Œå®šä¹‰ IFC å±æ€§é›†å’Œæ„ä»¶å±æ€§ã€‚\n\n"
        "- ä¸åš BIM æ•°æ®è¾“å‡ºå¯ç•™ç©º"
    ),
}

with col_editor:
    # â”€â”€ Auto-init empty project so editor is always visible â”€â”€
    if not st.session_state.project:
        st.session_state.project = HSFProject.create_new(
            "untitled", work_dir=st.session_state.work_dir
        )
    proj_now = st.session_state.project
    _ev      = st.session_state.editor_version

    # â”€â”€ Row 1: Import (left) | ğŸ”§ ç¼–è¯‘ (right, primary/prominent) â”€â”€
    tb_import, tb_compile_top = st.columns([1.8, 2.2])

    with tb_import:
        any_upload = st.file_uploader(
            "ğŸ“‚ å¯¼å…¥ gdl / txt / gsm", type=["gdl", "txt", "gsm"],
            key="editor_import",
            help=".gdl/.txt â†’ è§£æè„šæœ¬  |  .gsm â†’ LP_XMLConverter è§£åŒ…",
        )
        if any_upload:
            # Dedup: skip if this exact file was already processed this session
            _fkey = f"{any_upload.name}_{any_upload.size}"
            if st.session_state._import_key_done != _fkey:
                ok, _imp_msg = _handle_unified_import(any_upload)
                if ok:
                    st.session_state._import_key_done = _fkey
                    st.rerun()
                else:
                    st.error(_imp_msg)

    with tb_compile_top:
        # GSM name input + compile button stacked in this column
        gsm_name_input = st.text_input(
            "GSMåç§°", label_visibility="collapsed",
            value=st.session_state.pending_gsm_name or proj_now.name,
            placeholder="è¾“å‡º GSM åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰",
            key="toolbar_gsm_name",
            help="ç¼–è¯‘è¾“å‡ºæ–‡ä»¶å",
        )
        st.session_state.pending_gsm_name = gsm_name_input
        if st.button("ğŸ”§  ç¼–  è¯‘  GSM", type="primary", use_container_width=True,
                     help="å°†å½“å‰æ‰€æœ‰è„šæœ¬ç¼–è¯‘ä¸º ArchiCAD .gsm å¯¹è±¡"):
            with st.spinner("ç¼–è¯‘ä¸­..."):
                success, result_msg = do_compile(
                    proj_now,
                    gsm_name=gsm_name_input or proj_now.name,
                    instruction="(toolbar compile)",
                )
            st.session_state.chat_history.append({"role": "assistant", "content": result_msg})
            if success:
                st.toast("âœ… ç¼–è¯‘æˆåŠŸ", icon="ğŸ—ï¸")
            else:
                st.error(result_msg)
            st.rerun()

    # â”€â”€ Row 2: Secondary toolbar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    tb_extract, tb_clear, tb_check = st.columns([1.5, 1.0, 1.2])

    with tb_extract:
        n_blocks = sum(
            1 for m in st.session_state.chat_history
            if m.get("role") == "assistant" and "```" in m.get("content", "")
        )
        lbl = f"ğŸ“¥ æå–({n_blocks})" if n_blocks else "ğŸ“¥ æå–"
        if st.button(lbl, use_container_width=True,
                     help="ä» AI å¯¹è¯ä¸­æå– GDL ä»£ç å—å†™å…¥ç¼–è¾‘å™¨"):
            extracted = _extract_gdl_from_chat()
            if extracted:
                sc, pc = _apply_scripts_to_project(proj_now, extracted)
                st.session_state.editor_version += 1
                parts = []
                if sc: parts.append(f"{sc} ä¸ªè„šæœ¬")
                if pc: parts.append(f"{pc} ä¸ªå‚æ•°")
                st.toast(f"ğŸ“¥ å·²å†™å…¥ {'ã€'.join(parts)}", icon="âœ…")
                st.rerun()
            else:
                st.toast("å¯¹è¯ä¸­æœªå‘ç° GDL/paramlist ä»£ç å—", icon="â„¹ï¸")

    with tb_clear:
        if st.button("ğŸ—‘ï¸ æ¸…ç©º", use_container_width=True, help="é‡ç½®é¡¹ç›®ï¼šè„šæœ¬ã€å‚æ•°ã€å¯¹è¯ã€æ—¥å¿—å…¨æ¸…ï¼Œä¿ç•™è®¾ç½®"):
            st.session_state.confirm_clear = True

    with tb_check:
        if st.button("ğŸ” å…¨æ£€æŸ¥", use_container_width=True):
            all_ok = True
            for stype, fpath, label in _SCRIPT_MAP:
                content = proj_now.get_script(stype)
                if not content:
                    continue
                skey = fpath.replace("scripts/", "").replace(".gdl", "")
                for iss in check_gdl_script(content, skey):
                    if iss.startswith("âœ…"):
                        st.success(f"{label}: {iss}")
                    else:
                        st.warning(f"{label}: {iss}")
                        all_ok = False
            if all_ok:
                st.success("âœ… æ‰€æœ‰è„šæœ¬è¯­æ³•æ­£å¸¸")

    # â”€â”€ æ¸…ç©ºç¡®è®¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if st.session_state.get("confirm_clear"):
        st.warning("âš ï¸ å°†é‡ç½®é¡¹ç›®ï¼ˆè„šæœ¬ã€å‚æ•°ã€ç¼–è¯‘æ—¥å¿—ï¼‰ï¼ŒèŠå¤©è®°å½•ä¿ç•™ã€‚ç¡®è®¤ç»§ç»­ï¼Ÿ")
        cc1, cc2, _ = st.columns([1, 1, 4])
        with cc1:
            if st.button("âœ… ç¡®è®¤æ¸…ç©º", type="primary"):
                _keep_work_dir = st.session_state.work_dir
                _keep_api_keys = st.session_state.model_api_keys
                _keep_chat     = st.session_state.chat_history   # preserve chat
                st.session_state.project          = None
                st.session_state.compile_log      = []
                st.session_state.pending_diffs    = {}
                st.session_state.pending_ai_label = ""
                st.session_state.pending_gsm_name = ""
                st.session_state.agent_running    = False
                st.session_state._import_key_done = ""
                st.session_state.confirm_clear    = False
                st.session_state.editor_version  += 1
                st.session_state.work_dir         = _keep_work_dir
                st.session_state.model_api_keys   = _keep_api_keys
                st.session_state.chat_history     = _keep_chat
                st.toast("ğŸ—‘ï¸ å·²é‡ç½®é¡¹ç›®ï¼ˆè„šæœ¬ã€å‚æ•°ã€æ—¥å¿—ï¼‰ï¼ŒèŠå¤©è®°å½•ä¿ç•™", icon="âœ…")
                st.rerun()
        with cc2:
            if st.button("âŒ å–æ¶ˆ"):
                st.session_state.confirm_clear = False
                st.rerun()

    # â”€â”€ Pending AI changes banner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if st.session_state.pending_diffs:
        _label = st.session_state.pending_ai_label or "AI ç”Ÿæˆçš„å†…å®¹"
        _n_scripts = sum(1 for k in st.session_state.pending_diffs if k.startswith("scripts/"))
        _n_params  = len(_parse_paramlist_text(
            st.session_state.pending_diffs.get("paramlist.xml", "")
        ))
        _summary = []
        if _n_scripts: _summary.append(f"{_n_scripts} ä¸ªè„šæœ¬")
        if _n_params:  _summary.append(f"{_n_params} ä¸ªå‚æ•°")
        _banner_txt = "ã€".join(_summary) if _summary else _label

        st.info(f"ğŸ¤– **AI å»ºè®®äº†æ–°çš„ {_banner_txt}** â€” æ˜¯å¦å†™å…¥ç¼–è¾‘å™¨ï¼Ÿ")
        _pb1, _pb2, _pb3 = st.columns([1.2, 1, 6])
        with _pb1:
            if st.button("âœ… å†™å…¥", type="primary", use_container_width=True, key="pending_apply"):
                sc, pc = _apply_scripts_to_project(proj_now, st.session_state.pending_diffs)
                st.session_state.pending_diffs    = {}
                st.session_state.pending_ai_label = ""
                st.session_state.editor_version  += 1
                applied = []
                if sc: applied.append(f"{sc} ä¸ªè„šæœ¬")
                if pc: applied.append(f"{pc} ä¸ªå‚æ•°")
                st.toast(f"âœ… å·²å†™å…¥ {'ã€'.join(applied)}", icon="âœï¸")
                st.rerun()
        with _pb2:
            if st.button("ğŸ—‘ï¸ å¿½ç•¥", use_container_width=True, key="pending_discard"):
                st.session_state.pending_diffs    = {}
                st.session_state.pending_ai_label = ""
                st.rerun()

    st.divider()

    # â”€â”€ Script / Param Tabs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    tab_labels = ["å‚æ•°"] + [lbl for _, _, lbl in _SCRIPT_MAP] + ["ğŸ“‹ æ—¥å¿—"]
    all_tabs   = st.tabs(tab_labels)
    tab_params, *script_tabs, tab_log = all_tabs

    # Params tab
    with tab_params:
        with st.expander("â„¹ï¸ å‚æ•°è¯´æ˜"):
            st.markdown(
                "**å‚æ•°åˆ—è¡¨** â€” GDL å¯¹è±¡çš„å¯è°ƒå‚æ•°ã€‚\n\n"
                "- **Type**: `Length` / `Integer` / `Boolean` / `Material` / `String`\n"
                "- **Name**: ä»£ç ä¸­å¼•ç”¨çš„å˜é‡åï¼ˆcamelCaseï¼Œå¦‚ `iShelves`ï¼‰\n"
                "- **Value**: é»˜è®¤å€¼\n"
                "- **Fixed**: å‹¾é€‰åç”¨æˆ·æ— æ³•åœ¨ ArchiCAD ä¸­ä¿®æ”¹"
            )
        param_data = [
            {"Type": p.type_tag, "Name": p.name, "Value": p.value,
             "Description": p.description, "Fixed": "âœ“" if p.is_fixed else ""}
            for p in proj_now.parameters
        ]
        if param_data:
            st.dataframe(param_data, use_container_width=True, hide_index=True)
        else:
            st.caption("æš‚æ— å‚æ•°ï¼Œé€šè¿‡ AI å¯¹è¯æ·»åŠ ï¼Œæˆ–æ‰‹åŠ¨æ·»åŠ ã€‚")

        with st.expander("â• æ‰‹åŠ¨æ·»åŠ å‚æ•°"):
            pc1, pc2, pc3, pc4 = st.columns(4)
            with pc1:
                p_type = st.selectbox("Type", [
                    "Length", "Integer", "Boolean", "RealNum", "Angle",
                    "String", "Material", "FillPattern", "LineType", "PenColor",
                ])
            with pc2:
                p_name = st.text_input("Name", value="bNewParam")
            with pc3:
                p_value = st.text_input("Value", value="0")
            with pc4:
                p_desc = st.text_input("Description")
            if st.button("æ·»åŠ å‚æ•°"):
                try:
                    proj_now.add_parameter(GDLParameter(p_name, p_type, p_desc, p_value))
                    st.success(f"âœ… {p_type} {p_name}")
                    st.rerun()
                except Exception as e:
                    st.error(str(e))

        if st.button("ğŸ” éªŒè¯å‚æ•°"):
            issues = validate_paramlist(proj_now.parameters)
            for i in issues:
                st.warning(i)
            if not issues:
                st.success("âœ… å‚æ•°éªŒè¯é€šè¿‡")

        with st.expander("paramlist.xml é¢„è§ˆ"):
            st.code(build_paramlist_xml(proj_now.parameters), language="xml")

    # Script tabs
    for tab, (stype, fpath, label) in zip(script_tabs, _SCRIPT_MAP):
        with tab:
            _tab_help_col, _tab_fs_col = st.columns([6, 1])
            with _tab_help_col:
                with st.expander(f"â„¹ï¸ {label} è„šæœ¬è¯´æ˜"):
                    st.markdown(_SCRIPT_HELP.get(fpath, ""))
            with _tab_fs_col:
                if st.button("â›¶", key=f"fs_{fpath}_v{_ev}",
                             help="å…¨å±ç¼–è¾‘", use_container_width=True):
                    _fullscreen_editor_dialog(stype, fpath, label)

            current_code = proj_now.get_script(stype) or ""
            skey = fpath.replace("scripts/", "").replace(".gdl", "")

            if _ACE_AVAILABLE:
                _raw_ace = st_ace(
                    value=current_code,
                    language="fortran",   # closest built-in: `!` comments + keyword structure
                    theme="monokai",
                    height=280,
                    font_size=13,
                    tab_size=2,
                    show_gutter=True,
                    show_print_margin=False,
                    wrap=False,
                    key=f"ace_{fpath}_v{_ev}",
                )
                # st_ace returns None on first render (widget not yet initialized).
                # NEVER let None â†’ "" silently overwrite real script content.
                new_code = _raw_ace if _raw_ace is not None else current_code
            else:
                new_code = st.text_area(
                    label, value=current_code, height=280,
                    key=f"script_{fpath}_v{_ev}", label_visibility="collapsed",
                ) or ""  # text_area never returns None; empty string is a valid clear

            if new_code != current_code:
                proj_now.set_script(stype, new_code)
            if st.button("ğŸ” æ£€æŸ¥", key=f"chk_{fpath}_v{_ev}"):
                for iss in check_gdl_script(new_code, skey):
                    st.success(iss) if iss.startswith("âœ…") else st.warning(iss)

    # Log tab
    with tab_log:
        if not st.session_state.compile_log:
            st.info("æš‚æ— ç¼–è¯‘è®°å½•")
        else:
            for entry in reversed(st.session_state.compile_log):
                icon = "âœ…" if entry["success"] else "âŒ"
                st.markdown(f"**{icon} {entry['project']}** â€” {entry.get('instruction','')}")
                st.code(entry["message"], language="text")
                st.divider()
        if st.button("æ¸…é™¤æ—¥å¿—"):
            st.session_state.compile_log = []
            st.rerun()
        with st.expander("HSF ç›®å½•ç»“æ„"):
            tree = [f"ğŸ“ {proj_now.name}/", "  â”œâ”€â”€ libpartdata.xml",
                    "  â”œâ”€â”€ paramlist.xml", "  â”œâ”€â”€ ancestry.xml", "  â””â”€â”€ scripts/"]
            for stype in ScriptType:
                if stype in proj_now.scripts:
                    n = proj_now.scripts[stype].count("\n") + 1
                    tree.append(f"       â”œâ”€â”€ {stype.value} ({n} lines)")
            st.code("\n".join(tree), language="text")


# â”€â”€ Right: AI Chat panel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with col_chat:
    _chat_proj = st.session_state.project
    if _chat_proj:
        st.markdown(f"### ğŸ’¬ {_chat_proj.name}")
        st.caption(f"å‚æ•°: {len(_chat_proj.parameters)} | è„šæœ¬: {len(_chat_proj.scripts)}")
    else:
        st.markdown("### ğŸ’¬ AI åŠ©æ‰‹")
        st.caption("æè¿°éœ€æ±‚ï¼ŒAI è‡ªåŠ¨åˆ›å»º GDL å¯¹è±¡å†™å…¥ç¼–è¾‘å™¨")

    # Chat history with action bar on each assistant message
    for _i, _msg in enumerate(st.session_state.chat_history):
        with st.chat_message(_msg["role"]):
            st.markdown(_msg["content"])
            if _msg["role"] == "assistant":
                _ca, _cb, _cc, _cd, _ce = st.columns([1, 1, 1, 1, 8])
                with _ca:
                    if st.button("ğŸ‘", key=f"like_{_i}", help="æœ‰å¸®åŠ©"):
                        _save_feedback(_i, "positive", _msg["content"])
                        st.toast("å·²è®°å½• ğŸ‘", icon="âœ…")
                with _cb:
                    if st.button("ğŸ‘", key=f"dislike_{_i}", help="éœ€æ”¹è¿›"):
                        _save_feedback(_i, "negative", _msg["content"])
                        st.toast("å·²è®°å½• ğŸ‘ï¼Œæ„Ÿè°¢åé¦ˆ")
                with _cc:
                    if st.button("ğŸ“‹", key=f"copy_{_i}", help="å±•å¼€å¯å¤åˆ¶å†…å®¹"):
                        _flag = f"_showcopy_{_i}"
                        st.session_state[_flag] = not st.session_state.get(_flag, False)
                with _cd:
                    _prev_user = next(
                        (st.session_state.chat_history[j]["content"]
                         for j in range(_i - 1, -1, -1)
                         if st.session_state.chat_history[j]["role"] == "user"),
                        None,
                    )
                    if _prev_user and st.button("ğŸ”„", key=f"redo_{_i}", help="é‡æ–°ç”Ÿæˆ"):
                        st.session_state.chat_history = st.session_state.chat_history[:_i]
                        st.session_state["_redo_input"] = _prev_user
                        st.rerun()
        if st.session_state.get(f"_showcopy_{_i}", False):
            st.code(_msg["content"], language="text")

    # Live agent output placeholder (anchored inside this column)
    live_output = st.empty()

    # Chat input â€” immediately below the message list / action bars
    user_input = st.chat_input(
        "æè¿°éœ€æ±‚æˆ–æé—®ï¼Œå¦‚ã€Œåˆ›å»ºä¸€ä¸ªå®½ 600mm çš„ä¹¦æ¶ã€"
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Chat handler (outside columns â€” session state + rerun)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_redo_input = st.session_state.pop("_redo_input", None)
effective_input = _redo_input or user_input

if effective_input:
    # Redo: user msg already in history; new: append it
    if not _redo_input:
        st.session_state.chat_history.append({"role": "user", "content": effective_input})
    user_input = effective_input   # alias for rest of handler

    if not api_key and "ollama" not in model_name:
        err = "âŒ è¯·åœ¨å·¦ä¾§è¾¹æ å¡«å…¥ API Key åå†è¯•ã€‚"
        st.session_state.chat_history.append({"role": "assistant", "content": err})
        st.rerun()
    else:
        llm_for_classify = get_llm()
        intent, gdl_obj_name = classify_and_extract(
            user_input, llm_for_classify,
            project_loaded=bool(st.session_state.project),
        )

        with live_output.container():
            st.chat_message("user").markdown(user_input)
            with st.chat_message("assistant"):
                if intent == "CHAT":
                    msg = chat_respond(
                        user_input,
                        st.session_state.chat_history[:-1],
                        llm_for_classify,
                    )
                    st.markdown(msg)
                else:
                    if not st.session_state.project:
                        new_proj = HSFProject.create_new(gdl_obj_name, work_dir=st.session_state.work_dir)
                        st.session_state.project = new_proj
                        st.session_state.pending_gsm_name = gdl_obj_name
                        st.info(f"ğŸ“ å·²åˆå§‹åŒ–é¡¹ç›® `{gdl_obj_name}`")

                    proj_current = st.session_state.project
                    effective_gsm = st.session_state.pending_gsm_name or proj_current.name
                    msg = run_agent_generate(
                        user_input, proj_current, st.container(),
                        gsm_name=effective_gsm,
                    )
                    st.markdown(msg)

        st.session_state.chat_history.append({"role": "assistant", "content": msg})
        st.rerun()


# â”€â”€ Footer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.divider()
st.markdown(
    '<p style="text-align:center; color:#64748b; font-size:0.8rem;">'
    'gdl-agent v0.5.0 Â· HSF-native Â·'
    '<a href="https://github.com/byewind/gdl-agent">GitHub</a>'
    '</p>',
    unsafe_allow_html=True,
)
