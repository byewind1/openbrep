"""
gdl-agent Web UI â€” Streamlit interface for architects.

Run: streamlit run ui/app.py
"""

import sys
import re
import os
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import streamlit as st

from gdl_agent.hsf_project import HSFProject, ScriptType, GDLParameter
from gdl_agent.gdl_parser import parse_gdl_source, parse_gdl_file
from gdl_agent.paramlist_builder import build_paramlist_xml, validate_paramlist
from gdl_agent.compiler import MockHSFCompiler, HSFCompiler, CompileResult
from gdl_agent.core import GDLAgent, Status
from gdl_agent.knowledge import KnowledgeBase
from gdl_agent.skills_loader import SkillsLoader


# â”€â”€ Page Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(
    page_title="gdl-agent",
    page_icon="ğŸ—ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â”€â”€ Custom CSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;600&family=Noto+Sans+SC:wght@300;400;600&display=swap');

.stApp { font-family: 'Noto Sans SC', sans-serif; }
code, .stCodeBlock { font-family: 'JetBrains Mono', monospace !important; }

.main-header {
    font-family: 'JetBrains Mono', monospace;
    font-size: 2rem; font-weight: 600;
    background: linear-gradient(135deg, #22d3ee, #34d399);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin-bottom: 0;
}
.sub-header { color: #94a3b8; font-size: 0.9rem; margin-top: -0.5rem; margin-bottom: 2rem; }

.welcome-card {
    background: linear-gradient(135deg, #0f172a, #1e293b);
    border: 1px solid #334155;
    border-radius: 12px;
    padding: 2rem;
    margin: 1rem 0;
}
.step-item {
    display: flex;
    align-items: flex-start;
    gap: 0.75rem;
    margin-bottom: 1rem;
    padding: 0.75rem;
    background: #1e293b;
    border-radius: 8px;
    border-left: 3px solid #22d3ee;
}
.diff-current { border-left: 3px solid #475569; padding-left: 0.5rem; }
.diff-ai      { border-left: 3px solid #f59e0b; padding-left: 0.5rem; }
.diff-badge {
    display: inline-block;
    background: #f59e0b22;
    color: #f59e0b;
    border: 1px solid #f59e0b55;
    border-radius: 4px;
    padding: 2px 8px;
    font-size: 0.78rem;
    font-family: 'JetBrains Mono', monospace;
    margin-bottom: 4px;
}
</style>
""", unsafe_allow_html=True)


# â”€â”€ Session State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if "project" not in st.session_state:
    st.session_state.project = None
if "compile_log" not in st.session_state:
    st.session_state.compile_log = []
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "work_dir" not in st.session_state:
    st.session_state.work_dir = str(Path.home() / "gdl-agent-workspace")
if "agent_running" not in st.session_state:
    st.session_state.agent_running = False
if "pending_diffs" not in st.session_state:
    # AI-proposed changes awaiting user review. {script_path: new_content}
    # e.g. {"scripts/3d.gdl": "...", "scripts/2d.gdl": "..."}
    st.session_state.pending_diffs = {}
if "pending_gsm_name" not in st.session_state:
    st.session_state.pending_gsm_name = ""
if "model_api_keys" not in st.session_state:
    # Per-model API Key storage â€” pre-fill from config.toml provider_keys
    st.session_state.model_api_keys = {}


# â”€â”€ Load config.toml defaults â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_config_defaults = {}
_provider_keys: dict = {}   # {provider: api_key}

try:
    from gdl_agent.config import GDLAgentConfig
    import sys as _sys, os as _os
    # Load raw TOML to get provider_keys nested table
    if _sys.version_info >= (3, 11):
        import tomllib as _tomllib
    else:
        import tomli as _tomllib   # type: ignore

    _toml_path = _os.path.join(_os.path.dirname(__file__), "..", "config.toml")
    if _os.path.exists(_toml_path):
        with open(_toml_path, "rb") as _f:
            _raw = _tomllib.load(_f)
        _provider_keys = _raw.get("llm", {}).get("provider_keys", {})

    _config = GDLAgentConfig.load()
    _config_defaults = {
        "llm_model": _config.llm.model,
        "compiler_path": _config.compiler.path or "",
    }
except Exception:
    pass


def _key_for_model(model: str) -> str:
    """Pick the right API Key from provider_keys based on model name."""
    m = model.lower()
    if "glm" in m:
        return _provider_keys.get("zhipu", "")
    elif "deepseek" in m and "ollama" not in m:
        return _provider_keys.get("deepseek", "")
    elif "claude" in m:
        return _provider_keys.get("anthropic", "")
    elif "gpt" in m or "o3" in m or "o1" in m:
        return _provider_keys.get("openai", "")
    elif "gemini" in m:
        return _provider_keys.get("google", "")
    return ""

# â”€â”€ Sidebar Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with st.sidebar:
    st.markdown('<p class="main-header">gdl-agent</p>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">v0.5.0 Â· HSF-native Â· AI-powered</p>', unsafe_allow_html=True)
    st.divider()

    st.subheader("ğŸ“ å·¥ä½œç›®å½•")
    work_dir = st.text_input("Work Directory", value=st.session_state.work_dir, label_visibility="collapsed")
    st.session_state.work_dir = work_dir

    st.divider()
    st.subheader("ğŸ”§ ç¼–è¯‘å™¨ / Compiler")

    compiler_mode = st.radio(
        "ç¼–è¯‘æ¨¡å¼",
        ["Mock (æ— éœ€ ArchiCAD)", "LP_XMLConverter (çœŸå®ç¼–è¯‘)"],
        index=1 if _config_defaults.get("compiler_path") else 0,
    )

    converter_path = ""
    if compiler_mode.startswith("LP"):
        converter_path = st.text_input(
            "LP_XMLConverter è·¯å¾„",
            value=_config_defaults.get("compiler_path", ""),
            placeholder="/Applications/GRAPHISOFT/ArchiCAD 28/LP_XMLConverter",
        )

    st.divider()
    st.subheader("ğŸ§  AI æ¨¡å‹ / LLM")

    model_options = [
        # â”€â”€ Anthropic Claude â”€â”€
        "claude-haiku-4-5-20251001",
        "claude-sonnet-4-5-20250929",
        "claude-opus-4-5-20250918",
        "claude-opus-4-6",
        # â”€â”€ æ™ºè°± GLM (Z.ai) â”€â”€
        "glm-4.7",
        "glm-4.7-flash",
        "glm-4-plus",
        "glm-4-flash",
        # â”€â”€ OpenAI â”€â”€
        "gpt-4o",
        "gpt-4o-mini",
        "o3-mini",
        # â”€â”€ DeepSeek â”€â”€
        "deepseek-chat",
        "deepseek-reasoner",
        # â”€â”€ Google Gemini â”€â”€
        "gemini/gemini-2.5-flash",
        "gemini/gemini-2.5-pro",
        # â”€â”€ Ollama æœ¬åœ° â”€â”€
        "ollama/qwen2.5:14b",
        "ollama/qwen3:8b",
        "ollama/deepseek-coder-v2:16b",
    ]

    default_model = _config_defaults.get("llm_model", "glm-4.7")
    default_index = model_options.index(default_model) if default_model in model_options else 4

    model_name = st.selectbox("æ¨¡å‹ / Model", model_options, index=default_index)

    # Load or initialize API Key for this specific model
    if model_name not in st.session_state.model_api_keys:
        # Auto-fill from config.toml provider_keys
        st.session_state.model_api_keys[model_name] = _key_for_model(model_name)

    api_key = st.text_input(
        "API Key",
        value=st.session_state.model_api_keys.get(model_name, ""),
        type="password",
        help="Ollama æœ¬åœ°æ¨¡å¼ä¸éœ€è¦ Key"
    )

    # Auto-save API Key if user manually edited it
    if api_key != st.session_state.model_api_keys.get(model_name, ""):
        st.session_state.model_api_keys[model_name] = api_key

    if "claude" in model_name:
        st.caption("ğŸ”‘ [è·å– Claude API Key â†’](https://console.anthropic.com/settings/keys)")
        st.caption("âš ï¸ API Key éœ€å•ç‹¬å……å€¼ï¼Œä¸ Claude Pro è®¢é˜…é¢åº¦æ— å…³")
    elif "glm" in model_name:
        st.caption("ğŸ”‘ [è·å–æ™ºè°± API Key â†’](https://bigmodel.cn/usercenter/apikeys)")
    elif "gpt" in model_name or "o3" in model_name:
        st.caption("ğŸ”‘ [è·å– OpenAI API Key â†’](https://platform.openai.com/api-keys)")
    elif "deepseek" in model_name and "ollama" not in model_name:
        st.caption("ğŸ”‘ [è·å– DeepSeek API Key â†’](https://platform.deepseek.com/api_keys)")
    elif "gemini" in model_name:
        st.caption("ğŸ”‘ [è·å– Gemini API Key â†’](https://aistudio.google.com/apikey)")
    elif "ollama" in model_name:
        st.caption("ğŸ–¥ï¸ æœ¬åœ°è¿è¡Œï¼Œæ— éœ€ Keyã€‚ç¡®ä¿ Ollama å·²å¯åŠ¨ã€‚")

    # API Base URL â€” only needed for OpenAI-compatible custom endpoints
    # zai/ (GLM), deepseek/, anthropic/ are native LiteLLM providers, no api_base needed
    def _get_default_api_base(model: str) -> str:
        m = model.lower()
        if "ollama" in m:
            return "http://localhost:11434"
        # GLM uses zai/ native provider â€” no api_base
        # DeepSeek uses deepseek/ native provider â€” no api_base
        return ""

    default_api_base = _get_default_api_base(model_name)
    api_base = ""
    if default_api_base:
        api_base = st.text_input("API Base URL", value=default_api_base)

    max_retries = st.slider("æœ€å¤§é‡è¯•æ¬¡æ•°", 1, 10, 5)

    st.divider()

    # Project info + quick reset
    if st.session_state.project:
        proj = st.session_state.project
        st.subheader(f"ğŸ“¦ {proj.name}")
        st.caption(f"å‚æ•°: {len(proj.parameters)} | è„šæœ¬: {len(proj.scripts)}")
        if st.button("ğŸ—‘ï¸ æ¸…é™¤é¡¹ç›®", use_container_width=True):
            st.session_state.project = None
            st.session_state.chat_history = []
            st.rerun()


# â”€â”€ Helper Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_compiler():
    if compiler_mode.startswith("Mock"):
        return MockHSFCompiler()
    return HSFCompiler(converter_path or None)

def get_llm():
    from gdl_agent.config import LLMConfig
    from gdl_agent.llm import LLMAdapter
    config = LLMConfig(
        model=model_name,
        api_key=api_key,
        api_base=api_base,
        temperature=0.2,
        max_tokens=4096,
    )
    return LLMAdapter(config)

def load_knowledge(task_type: str = "all"):
    kb_dir = Path(st.session_state.work_dir) / "knowledge"
    if not kb_dir.exists():
        kb_dir = Path(__file__).parent.parent / "knowledge"
    kb = KnowledgeBase(str(kb_dir))
    kb.load()
    return kb.get_by_task_type(task_type)

def load_skills():
    sk_dir = Path(st.session_state.work_dir) / "skills"
    if not sk_dir.exists():
        sk_dir = Path(__file__).parent.parent / "skills"
    sl = SkillsLoader(str(sk_dir))
    sl.load()
    return sl

def _versioned_gsm_path(proj_name: str, work_dir: str) -> str:
    """
    Return next available versioned GSM path.
    MyShelf_v1.gsm â†’ MyShelf_v2.gsm â†’ ...
    Preserves all previous compilations.
    """
    out_dir = Path(work_dir) / "output"
    out_dir.mkdir(parents=True, exist_ok=True)
    v = 1
    while (out_dir / f"{proj_name}_v{v}.gsm").exists():
        v += 1
    return str(out_dir / f"{proj_name}_v{v}.gsm")


# â”€â”€ Object Name Extraction (dictionary + regex, no LLM) â”€â”€

_CN_TO_NAME = {
    # å®¶å…·
    "ä¹¦æ¶": "Bookshelf", "ä¹¦æŸœ": "Bookcase", "æŸœå­": "Cabinet", "è¡£æŸœ": "Wardrobe",
    "æ¡Œå­": "Table", "æ¡Œ": "Table", "ä¹¦æ¡Œ": "Desk", "é¤æ¡Œ": "DiningTable",
    "æ¤…å­": "Chair", "æ¤…": "Chair", "æ²™å‘": "Sofa", "åºŠ": "Bed",
    "èŒ¶å‡ ": "CoffeeTable", "ç”µè§†æŸœ": "TVStand", "é‹æŸœ": "ShoeRack",
    # å»ºç­‘æ„ä»¶
    "çª—": "Window", "çª—æ¡†": "WindowFrame", "çª—æˆ·": "Window", "ç™¾å¶çª—": "Louver",
    "é—¨": "Door", "é—¨æ¡†": "DoorFrame", "æ¨æ‹‰é—¨": "SlidingDoor", "æ—‹è½¬é—¨": "RevolvingDoor",
    "å¢™": "Wall", "å¢™æ¿": "WallPanel", "éš”å¢™": "Partition", "å¹•å¢™": "CurtainWall",
    "æ¥¼æ¢¯": "Staircase", "å°é˜¶": "StairStep", "æ‰¶æ‰‹": "Handrail", "æ æ†": "Railing",
    "æŸ±": "Column", "æŸ±å­": "Column", "æ¢": "Beam", "æ¿": "Slab",
    "å±‹é¡¶": "Roof", "å¤©èŠ±": "Ceiling", "åœ°æ¿": "Floor",
    # è®¾å¤‡
    "ç¯": "Light", "ç¯å…·": "LightFixture", "ç®¡é“": "Pipe", "é£ç®¡": "Duct",
    "å¼€å…³": "Switch", "æ’åº§": "Outlet", "ç©ºè°ƒ": "AirConditioner",
    # æ™¯è§‚
    "èŠ±ç›†": "Planter", "æ ‘": "Tree", "å›´æ ": "Fence", "é•¿å‡³": "Bench",
}

def _extract_object_name(text: str) -> str:
    """
    Extract GDL object name from user input.
    Priority: explicit English name > Chinese keyword dict > fallback.
    Zero LLM calls â€” instant and 100% reliable.
    """
    # 1. Check for explicit English name: "named MyShelf", "å« MyShelf"
    for pat in [
        r'named?\s+([A-Za-z][A-Za-z0-9]{2,30})',
        r'called\s+([A-Za-z][A-Za-z0-9]{2,30})',
        r'åä¸º\s*([A-Za-z][A-Za-z0-9]{2,30})',
        r'å«\s*([A-Za-z][A-Za-z0-9]{2,30})',
    ]:
        m = re.search(pat, text, re.IGNORECASE)
        if m:
            return m.group(1)

    # 2. Chinese keyword â†’ English CamelCase (longest match first)
    for cn, en in sorted(_CN_TO_NAME.items(), key=lambda x: len(x[0]), reverse=True):
        if cn in text:
            print(f"[name] '{cn}' â†’ {en}")
            return en

    # 3. Pick first CamelCase English word in text (skip short junk like UI, AI, GDL)
    for word in re.findall(r'[A-Z][a-z]{2,}[A-Za-z0-9]*', text):
        if word not in {"The", "For", "And", "Not", "But", "With"}:
            return word

    return "MyObject"


# â”€â”€ Welcome / Onboarding Panel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def show_welcome():
    st.markdown("""
<div class="welcome-card">
<h2 style="color:#22d3ee; margin-top:0; font-family:'JetBrains Mono';">æ¬¢è¿ä½¿ç”¨ gdl-agent ğŸ—ï¸</h2>
<p style="color:#94a3b8;">ç”¨è‡ªç„¶è¯­è¨€é©±åŠ¨ ArchiCAD GDL å¯¹è±¡çš„åˆ›å»ºä¸ç¼–è¯‘ã€‚æ— éœ€äº†è§£ GDL è¯­æ³•ï¼Œç›´æ¥æè¿°éœ€æ±‚å³å¯ã€‚</p>
</div>
""", unsafe_allow_html=True)

    st.markdown("#### ä¸‰æ­¥å¿«é€Ÿå¼€å§‹")

    st.info("**â‘  é…ç½® API Key**  \nåœ¨å·¦ä¾§è¾¹æ é€‰æ‹© AI æ¨¡å‹ï¼Œå¡«å…¥å¯¹åº” API Keyã€‚å…è´¹çš„æ™ºè°± GLM å¯ç›´æ¥ä½¿ç”¨ã€‚")
    st.info("**â‘¡ å¼€å§‹å¯¹è¯**  \nåœ¨åº•éƒ¨è¾“å…¥æ¡†æè¿°ä½ æƒ³åˆ›å»ºçš„ GDL å¯¹è±¡ï¼Œä¾‹å¦‚ï¼š  \nã€Œåˆ›å»ºä¸€ä¸ªå®½ 600mmã€æ·± 400mm çš„ä¹¦æ¶ï¼Œå¸¦ iShelves å‚æ•°æ§åˆ¶å±‚æ•°ã€")
    st.info("**â‘¢ ç¼–è¯‘è¾“å‡º**  \nAI ç”Ÿæˆä»£ç åè‡ªåŠ¨è§¦å‘ç¼–è¯‘ã€‚çœŸå®ç¼–è¯‘éœ€åœ¨ä¾§è¾¹æ é…ç½® LP_XMLConverter è·¯å¾„ã€‚Mock æ¨¡å¼å¯éªŒè¯ç»“æ„ï¼Œæ— éœ€å®‰è£… ArchiCADã€‚")

    st.divider()

    st.markdown("#### æˆ–è€…ï¼šå¯¼å…¥å·²æœ‰ GDL æ–‡ä»¶")
    uploaded_file = st.file_uploader(
        "æ‹–å…¥ .gdl æ–‡ä»¶å¼€å§‹ç¼–è¾‘",
        type=["gdl", "txt"],
        help="æ”¯æŒ AI ç”Ÿæˆæˆ–æ‰‹å†™çš„ GDL æºç ",
        key="welcome_upload",
    )
    if uploaded_file:
        content = uploaded_file.read().decode("utf-8", errors="replace")
        name = Path(uploaded_file.name).stem
        try:
            project = parse_gdl_source(content, name)
            project.work_dir = Path(st.session_state.work_dir)
            project.root = project.work_dir / project.name
            st.session_state.project = project
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": f"âœ… å·²å¯¼å…¥ `{project.name}` â€” {len(project.parameters)} ä¸ªå‚æ•°ï¼Œ{len(project.scripts)} ä¸ªè„šæœ¬ã€‚å¯ä»¥å¼€å§‹å¯¹è¯ä¿®æ”¹äº†ã€‚"
            })
            st.rerun()
        except Exception as e:
            st.error(f"âŒ å¯¼å…¥å¤±è´¥: {e}")

    st.divider()
    st.caption("ğŸ’¡ æç¤ºï¼šç¬¬ä¸€æ¡æ¶ˆæ¯æ— éœ€åˆ›å»ºé¡¹ç›®ï¼Œç›´æ¥æè¿°éœ€æ±‚ï¼ŒAI ä¼šè‡ªåŠ¨åˆå§‹åŒ–ã€‚")


# â”€â”€ Intent Classification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_GDL_KEYWORDS = [
    "åˆ›å»º", "ç”Ÿæˆ", "åˆ¶ä½œ", "åšä¸€ä¸ª", "å»ºä¸€ä¸ª", "å†™ä¸€ä¸ª",
    "ä¿®æ”¹", "æ›´æ–°", "æ·»åŠ ", "åˆ é™¤", "è°ƒæ•´", "ä¼˜åŒ–",
    "ä¹¦æ¶", "æŸœå­", "çª—", "é—¨", "å¢™", "æ¥¼æ¢¯", "æ¡Œ", "æ¤…",
    "å‚æ•°", "parameter", "script", "gdl", "gsm", "hsf",
    "compile", "ç¼–è¯‘", "build", "create", "make", "add",
    "3d", "2d", "prism", "block", "sphere",
]

def _is_gdl_intent(text: str) -> bool:
    """Quick keyword check â€” if obvious GDL request, skip LLM classification."""
    t = text.lower()
    return any(kw in t for kw in _GDL_KEYWORDS)

def classify_and_extract(text: str, llm) -> tuple:
    """
    Returns: (intent, obj_name)
    - intent: via keyword fast-path, LLM only for ambiguous cases
    - obj_name: dictionary + regex, zero LLM calls
    """
    # Name: always from dictionary (instant, no LLM)
    obj_name = _extract_object_name(text)

    # Intent fast-path
    if _is_gdl_intent(text):
        return ("GDL", obj_name)

    # Ambiguous â†’ ask LLM just for GDL/CHAT (one word)
    try:
        resp = llm.generate([
            {
                "role": "system",
                "content": (
                    "ä½ æ˜¯æ„å›¾åˆ†ç±»å™¨ã€‚åˆ¤æ–­ç”¨æˆ·æ˜¯å¦æƒ³åˆ›å»ºæˆ–ä¿®æ”¹ ArchiCAD GDL æ„ä»¶ã€‚\n"
                    "åªå›å¤ä¸€ä¸ªè¯ï¼šGDL æˆ– CHAT\n"
                    "GDL = è¦åˆ›å»º/ä¿®æ”¹/ç¼–è¯‘æ„ä»¶\n"
                    "CHAT = é—²èŠ/æ‰“æ‹›å‘¼/é—®ç”¨æ³•"
                ),
            },
            {"role": "user", "content": text},
        ], max_tokens=10, temperature=0.1)

        raw = resp.content.strip().upper()
        print(f"[classify] intent raw: '{raw}'")
        intent = "GDL" if "GDL" in raw else "CHAT"
        return (intent, obj_name)

    except Exception as e:
        print(f"[classify] exception: {e}")
        return ("CHAT", obj_name)


def chat_respond(user_input: str, history: list, llm) -> str:
    """Simple conversational response without triggering Agent."""
    system_msg = {
        "role": "system",
        "content": (
            "ä½ æ˜¯ gdl-agent çš„åŠ©æ‰‹ï¼Œä¸“æ³¨äº ArchiCAD GDL åº“æ„ä»¶çš„åˆ›å»ºä¸ç¼–è¯‘ã€‚"
            "ç”¨æˆ·å¯ä»¥å’Œä½ é—²èŠï¼Œä¹Ÿå¯ä»¥è®©ä½ åˆ›å»º GDL å¯¹è±¡ã€‚"
            "é—²èŠæ—¶è‡ªç„¶å›åº”ï¼Œç®€æ´å‹å¥½ï¼›æ¶‰åŠ GDL åˆ›å»ºéœ€æ±‚æ—¶æé†’ç”¨æˆ·ç›´æ¥æè¿°éœ€æ±‚å³å¯å¼€å§‹ç”Ÿæˆã€‚"
            "å›å¤ä½¿ç”¨ä¸­æ–‡ï¼Œä¸“ä¸šæœ¯è¯­ä¿ç•™è‹±æ–‡ï¼ˆGDLã€HSFã€ArchiCADã€paramlist ç­‰ï¼‰ã€‚"
        ),
    }
    messages = [system_msg]
    # Include recent history for context (last 6 messages)
    for msg in history[-6:]:
        messages.append({"role": msg["role"], "content": msg["content"]})
    messages.append({"role": "user", "content": user_input})

    try:
        resp = llm.generate(messages)
        return resp.content
    except Exception as e:
        return f"âŒ {str(e)}"


# â”€â”€ Run Agent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_agent_generate(user_input: str, proj: HSFProject, status_col, gsm_name: str = None) -> str:
    """
    Generate code only (no compile).
    Stores result in session_state.pending_diffs â€” shown inline in script tabs.
    """
    status_ph = status_col.empty()

    def on_event(event_type, data):
        if event_type == "analyze":
            scripts = data.get("affected_scripts", [])
            status_ph.info(f"ğŸ” åˆ†æä¸­... å½±å“è„šæœ¬: {', '.join(scripts)}")
        elif event_type == "attempt":
            status_ph.info("ğŸ§  è°ƒç”¨ AI ç”Ÿæˆä»£ç ...")
        elif event_type == "llm_response":
            status_ph.info(f"âœï¸ æ”¶åˆ° {data['length']} å­—ç¬¦ï¼Œè§£æä¸­...")

    try:
        llm = get_llm()
        knowledge = load_knowledge()
        skills_text = load_skills().get_for_task(user_input)

        agent = GDLAgent(llm=llm, compiler=get_compiler(), on_event=on_event)
        changes = agent.generate_only(
            instruction=user_input, project=proj,
            knowledge=knowledge, skills=skills_text,
        )
        status_ph.empty()

        if not changes:
            return "âŒ AI è¾“å‡ºæ— æ³•è§£æï¼Œè¯·é‡æ–°æè¿°éœ€æ±‚ã€‚"

        # Merge into pending_diffs (AI may partially update scripts)
        st.session_state.pending_diffs.update(changes)
        if gsm_name:
            st.session_state.pending_gsm_name = gsm_name

        script_names = ", ".join(
            p.replace("scripts/", "").replace(".gdl", "").upper()
            for p in changes.keys()
            if p.startswith("scripts/")
        )
        return f"âœï¸ **AI å·²ç”Ÿæˆä»£ç ** â€” è„šæœ¬ [{script_names}] å³ä¾§å‡ºç°å¯¹æ¯”è§†å›¾ï¼Œç¡®è®¤åç‚¹å‡»ã€Œæ›¿æ¢ã€ï¼Œæœ€åã€ŒğŸ”§ ç¼–è¯‘ã€ã€‚"

    except Exception as e:
        status_ph.empty()
        return f"âŒ **é”™è¯¯**: {str(e)}"


def do_compile(proj: HSFProject, gsm_name: str, instruction: str = "") -> tuple:
    """
    Compile current project state â†’ versioned GSM.
    Returns (success: bool, message: str).
    """
    try:
        output_gsm = _versioned_gsm_path(gsm_name or proj.name, st.session_state.work_dir)
        hsf_dir = proj.save_to_disk()
        result = get_compiler().hsf2libpart(str(hsf_dir), output_gsm)
        mock_tag = " [Mock]" if compiler_mode.startswith("Mock") else ""

        if result.success:
            st.session_state.compile_log.append({
                "project": proj.name, "instruction": instruction,
                "success": True, "attempts": 1, "message": "Success",
            })
            msg = f"âœ… **ç¼–è¯‘æˆåŠŸ{mock_tag}**\n\nğŸ“¦ `{output_gsm}`"
            if compiler_mode.startswith("Mock"):
                msg += "\n\nâš ï¸ Mock æ¨¡å¼ä¸ç”ŸæˆçœŸå® .gsmï¼Œåˆ‡æ¢ LP_XMLConverter è¿›è¡ŒçœŸå®ç¼–è¯‘ã€‚"
            return (True, msg)
        else:
            st.session_state.compile_log.append({
                "project": proj.name, "instruction": instruction,
                "success": False, "attempts": 1, "message": result.stderr,
            })
            return (False, f"âŒ **ç¼–è¯‘å¤±è´¥**\n\n```\n{result.stderr[:500]}\n```")
    except Exception as e:
        return (False, f"âŒ **é”™è¯¯**: {str(e)}")


def import_gsm(gsm_bytes: bytes, filename: str) -> tuple:
    """
    Decompile GSM â†’ HSF â†’ HSFProject.
    Returns (project | None, message).
    """
    import tempfile, shutil
    tmp = Path(tempfile.mkdtemp())
    gsm_path = tmp / filename
    gsm_path.write_bytes(gsm_bytes)
    hsf_out = tmp / "hsf_out"
    hsf_out.mkdir()
    result = get_compiler().libpart2hsf(str(gsm_path), str(hsf_out))
    if not result.success:
        shutil.rmtree(tmp, ignore_errors=True)
        return (None, f"âŒ GSM è§£åŒ…å¤±è´¥: {result.stderr}")
    try:
        # LP_XMLConverter creates a subdirectory named after the object
        subdirs = [d for d in hsf_out.iterdir() if d.is_dir()]
        hsf_dir = subdirs[0] if subdirs else hsf_out
        proj = HSFProject.from_hsf(str(hsf_dir))
        proj.work_dir = Path(st.session_state.work_dir)
        proj.root = proj.work_dir / proj.name
        return (proj, f"âœ… å·²å¯¼å…¥ `{proj.name}` â€” {len(proj.parameters)} å‚æ•°ï¼Œ{len(proj.scripts)} è„šæœ¬")
    except Exception as e:
        return (None, f"âŒ HSF è§£æå¤±è´¥: {e}")
    finally:
        shutil.rmtree(tmp, ignore_errors=True)


def check_gdl_script(content: str, script_type: str = "") -> list:
    """
    Basic GDL syntax check. Returns list of warning strings (empty = OK).
    Checks: IF/ENDIF, FOR/NEXT, ADD/DEL balance, END in 3D, PROJECT2 in 2D.
    """
    import re as _re
    issues = []
    if not content.strip():
        if script_type == "2d":
            issues.append("âš ï¸ 2D è„šæœ¬ä¸ºç©ºï¼Œå¿…é¡»è‡³å°‘åŒ…å« PROJECT2 3, 270, 2")
        return issues

    lines = content.splitlines()

    # IF/ENDIF balance (only multi-line IF: IF ... THEN at end of line)
    if_multi = sum(
        1 for l in lines
        if _re.search(r'\bIF\b', l, _re.I)
        and _re.search(r'\bTHEN\s*$', l.strip(), _re.I)
    )
    endif_count = sum(1 for l in lines if _re.match(r'\s*ENDIF\b', l, _re.I))
    if if_multi != endif_count:
        issues.append(f"âš ï¸ IF/ENDIF ä¸åŒ¹é…ï¼š{if_multi} ä¸ªå¤šè¡Œ IFï¼Œ{endif_count} ä¸ª ENDIF")

    # FOR/NEXT balance
    for_count = sum(1 for l in lines if _re.match(r'\s*FOR\b', l, _re.I))
    next_count = sum(1 for l in lines if _re.match(r'\s*NEXT\b', l, _re.I))
    if for_count != next_count:
        issues.append(f"âš ï¸ FOR/NEXT ä¸åŒ¹é…ï¼š{for_count} ä¸ª FORï¼Œ{next_count} ä¸ª NEXT")

    # ADD/DEL balance
    add_count = sum(1 for l in lines if _re.match(r'\s*ADD\b', l, _re.I))
    del_count = sum(1 for l in lines if _re.match(r'\s*DEL\b', l, _re.I))
    if add_count != del_count:
        issues.append(f"âš ï¸ ADD/DEL ä¸åŒ¹é…ï¼š{add_count} ä¸ª ADDï¼Œ{del_count} ä¸ª DEL")

    # 3D: must end with END
    if script_type == "3d":
        last_non_empty = next(
            (l.strip() for l in reversed(lines) if l.strip()), ""
        )
        if not _re.match(r'^END\s*$', last_non_empty, _re.I):
            issues.append("âš ï¸ 3D è„šæœ¬æœ€åä¸€è¡Œå¿…é¡»æ˜¯ END")

    # 2D: must have projection
    if script_type == "2d":
        has_proj = any(
            _re.search(r'\bPROJECT2\b|\bRECT2\b|\bPOLY2\b', l, _re.I)
            for l in lines
        )
        if not has_proj:
            issues.append("âš ï¸ 2D è„šæœ¬ç¼ºå°‘å¹³é¢æŠ•å½±è¯­å¥ï¼ˆPROJECT2 / RECT2ï¼‰")

    if not issues:
        issues = ["âœ… æ£€æŸ¥é€šè¿‡"]
    return issues


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Main Layout: Left Chat | Right Editor
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

col_chat, col_editor = st.columns([2, 3], gap="large")


# â”€â”€ Left: Chat History â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with col_chat:
    if not st.session_state.project:
        st.markdown("### ğŸ’¬ å¼€å§‹åˆ›å»º")
        st.markdown(
            '<p style="color:#64748b; font-size:0.9rem;">åœ¨åº•éƒ¨è¾“å…¥æ¡†æè¿°ä½ æƒ³åˆ›å»ºçš„å¯¹è±¡ï¼ŒAI ä¼šè‡ªåŠ¨ç”Ÿæˆå¹¶ç¼–è¯‘ã€‚</p>',
            unsafe_allow_html=True,
        )
    else:
        proj_now = st.session_state.project
        st.markdown(f"### ğŸ’¬ {proj_now.name}")
        st.caption(f"å‚æ•°: {len(proj_now.parameters)} | è„šæœ¬: {len(proj_now.scripts)}")

    # Chat history
    for msg in st.session_state.chat_history:
        st.chat_message(msg["role"]).markdown(msg["content"])

    # Placeholder for live agent output (populated when agent runs)
    live_output = st.empty()


# â”€â”€ Right: Editor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_SCRIPT_MAP = [
    (ScriptType.SCRIPT_3D, "scripts/3d.gdl",  "3D"),
    (ScriptType.SCRIPT_2D, "scripts/2d.gdl",  "2D"),
    (ScriptType.MASTER,    "scripts/1d.gdl",  "Master"),
    (ScriptType.PARAM,     "scripts/vl.gdl",  "Param"),
    (ScriptType.UI,        "scripts/ui.gdl",  "UI"),
    (ScriptType.PROPERTIES,"scripts/pr.gdl",  "Properties"),
]

def _diff_summary(old: str, new: str) -> str:
    """Return a short +N/-N line diff summary."""
    old_lines = set(old.splitlines())
    new_lines = set(new.splitlines())
    added   = len(new_lines - old_lines)
    removed = len(old_lines - new_lines)
    return f"+{added} / -{removed} lines"


with col_editor:
    if not st.session_state.project:
        show_welcome()
    else:
        proj_now = st.session_state.project
        diffs    = st.session_state.pending_diffs  # live reference

        # â”€â”€ Toolbar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        tb_imp, tb_gsm_imp, tb_sep, tb_name, tb_compile, tb_check = st.columns(
            [1.2, 1.4, 0.2, 2.2, 1.4, 1.2]
        )

        # Import GDL (.gdl / .txt)
        with tb_imp:
            gdl_upload = st.file_uploader(
                "ğŸ“‚ GDL", type=["gdl", "txt"], label_visibility="collapsed",
                key="toolbar_gdl_upload", help="å¯¼å…¥ .gdl æ–‡ä»¶"
            )
            if gdl_upload:
                content = gdl_upload.read().decode("utf-8", errors="replace")
                name = Path(gdl_upload.name).stem
                try:
                    imported = parse_gdl_source(content, name)
                    imported.work_dir = Path(st.session_state.work_dir)
                    imported.root = imported.work_dir / imported.name
                    st.session_state.project = imported
                    st.session_state.pending_diffs = {}
                    st.session_state.pending_gsm_name = imported.name
                    st.session_state.chat_history.append({
                        "role": "assistant",
                        "content": f"âœ… å·²å¯¼å…¥ `{imported.name}` â€” {len(imported.parameters)} å‚æ•°ï¼Œ{len(imported.scripts)} è„šæœ¬",
                    })
                    st.rerun()
                except Exception as e:
                    st.error(f"å¯¼å…¥å¤±è´¥: {e}")

        # Import GSM (LP mode only)
        with tb_gsm_imp:
            if compiler_mode.startswith("LP"):
                gsm_upload = st.file_uploader(
                    "ğŸ“¦ GSM", type=["gsm"], label_visibility="collapsed",
                    key="toolbar_gsm_upload", help="å¯¼å…¥ .gsm â€” éœ€ LP_XMLConverter"
                )
                if gsm_upload:
                    with st.spinner("è§£åŒ… GSM..."):
                        proj_imp, imp_msg = import_gsm(gsm_upload.read(), gsm_upload.name)
                    if proj_imp:
                        st.session_state.project = proj_imp
                        st.session_state.pending_diffs = {}
                        st.session_state.pending_gsm_name = proj_imp.name
                        st.session_state.chat_history.append({"role": "assistant", "content": imp_msg})
                        st.rerun()
                    else:
                        st.error(imp_msg)
            else:
                st.caption("GSM å¯¼å…¥éœ€ LP æ¨¡å¼")

        # GSM output name
        with tb_name:
            gsm_name_input = st.text_input(
                "ğŸ“¦", label_visibility="collapsed",
                value=st.session_state.pending_gsm_name or proj_now.name,
                placeholder="è¾“å‡º GSM åç§°",
                key="toolbar_gsm_name",
                help="ç¼–è¯‘è¾“å‡ºæ–‡ä»¶åï¼ˆä¸å«ç‰ˆæœ¬å·å’Œæ‰©å±•åï¼‰",
            )
            st.session_state.pending_gsm_name = gsm_name_input

        # Compile button
        with tb_compile:
            n_diffs = len(diffs)
            compile_label = f"ğŸ”§ ç¼–è¯‘ ({n_diffs}â†‘)" if n_diffs else "ğŸ”§ ç¼–è¯‘"
            if st.button(compile_label, type="primary", use_container_width=True,
                         help="ç¼–è¯‘å½“å‰æ‰€æœ‰è„šæœ¬ï¼ˆæ¥å—çš„ AI å»ºè®®å·²è‡ªåŠ¨åº”ç”¨ï¼‰"):
                with st.spinner("ç¼–è¯‘ä¸­..."):
                    success, result_msg = do_compile(
                        proj_now,
                        gsm_name=gsm_name_input or proj_now.name,
                        instruction="(toolbar compile)",
                    )
                st.session_state.chat_history.append({"role": "assistant", "content": result_msg})
                if success:
                    st.toast("âœ… ç¼–è¯‘æˆåŠŸ", icon="ğŸ—ï¸")
                else:
                    st.error(result_msg)
                st.rerun()

        # Global syntax check
        with tb_check:
            if st.button("ğŸ” å…¨æ£€æŸ¥", use_container_width=True):
                all_ok = True
                for stype, fpath, label in _SCRIPT_MAP:
                    content = proj_now.get_script(stype)
                    if not content:
                        continue
                    skey = fpath.replace("scripts/", "").replace(".gdl", "")
                    for iss in check_gdl_script(content, skey):
                        if iss.startswith("âœ…"):
                            st.success(f"{label}: {iss}")
                        else:
                            st.warning(f"{label}: {iss}")
                            all_ok = False
                if all_ok:
                    st.success("âœ… æ‰€æœ‰è„šæœ¬è¯­æ³•æ­£å¸¸")

        st.divider()

        # â”€â”€ Tab strip â€” labels show â— when diff pending â”€â”€
        def _tlabel(name, fpath):
            return f"{name} â—" if fpath in diffs else name

        tab_labels = (
            ["å‚æ•°"]
            + [_tlabel(label, fpath) for _, fpath, label in _SCRIPT_MAP]
            + ["ğŸ“‹ æ—¥å¿—"]
        )
        all_tabs = st.tabs(tab_labels)
        tab_params = all_tabs[0]
        script_tabs = all_tabs[1:-1]
        tab_log = all_tabs[-1]

        # â”€â”€ å‚æ•° Tab â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with tab_params:
            param_data = [
                {"Type": p.type_tag, "Name": p.name, "Value": p.value,
                 "Description": p.description, "Fixed": "âœ“" if p.is_fixed else ""}
                for p in proj_now.parameters
            ]
            if param_data:
                st.dataframe(param_data, use_container_width=True, hide_index=True)
            else:
                st.caption("æš‚æ— å‚æ•°ï¼Œé€šè¿‡å¯¹è¯è®© AI æ·»åŠ ï¼Œæˆ–æ‰‹åŠ¨æ·»åŠ ã€‚")

            with st.expander("â• æ‰‹åŠ¨æ·»åŠ å‚æ•°"):
                pc1, pc2, pc3, pc4 = st.columns(4)
                with pc1:
                    p_type = st.selectbox("Type", [
                        "Length", "Integer", "Boolean", "RealNum", "Angle",
                        "String", "Material", "FillPattern", "LineType", "PenColor",
                    ])
                with pc2:
                    p_name = st.text_input("Name", value="bNewParam")
                with pc3:
                    p_value = st.text_input("Value", value="0")
                with pc4:
                    p_desc = st.text_input("Description")
                if st.button("æ·»åŠ å‚æ•°"):
                    try:
                        proj_now.add_parameter(GDLParameter(p_name, p_type, p_desc, p_value))
                        st.success(f"âœ… {p_type} {p_name}")
                        st.rerun()
                    except Exception as e:
                        st.error(str(e))

            if st.button("ğŸ” éªŒè¯å‚æ•°"):
                issues = validate_paramlist(proj_now.parameters)
                for i in issues:
                    st.warning(i)
                if not issues:
                    st.success("âœ… å‚æ•°éªŒè¯é€šè¿‡")

            with st.expander("paramlist.xml é¢„è§ˆ"):
                st.code(build_paramlist_xml(proj_now.parameters), language="xml")

        # â”€â”€ Script Tabs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for tab, (stype, fpath, label) in zip(script_tabs, _SCRIPT_MAP):
            with tab:
                current_code = proj_now.get_script(stype) or ""
                skey = fpath.replace("scripts/", "").replace(".gdl", "")
                has_diff = fpath in diffs

                if has_diff:
                    ai_code = diffs[fpath]
                    summary = _diff_summary(current_code, ai_code)

                    # â”€â”€ Diff view: current (left) | AI (right) â”€â”€
                    col_cur, col_ai = st.columns(2, gap="small")

                    with col_cur:
                        st.markdown(
                            '<div class="diff-current"><b>å½“å‰ä»£ç </b></div>',
                            unsafe_allow_html=True,
                        )
                        edited_cur = st.text_area(
                            "current", value=current_code, height=340,
                            key=f"cur_{fpath}", label_visibility="collapsed",
                        )
                        if edited_cur != current_code:
                            proj_now.set_script(stype, edited_cur)

                    with col_ai:
                        st.markdown(
                            f'<div class="diff-ai"><b>AI å»ºè®®</b> &nbsp;'
                            f'<span class="diff-badge">{summary}</span></div>',
                            unsafe_allow_html=True,
                        )
                        edited_ai = st.text_area(
                            "ai", value=ai_code, height=340,
                            key=f"ai_{fpath}", label_visibility="collapsed",
                        )
                        diffs[fpath] = edited_ai  # track in-place edits to AI side

                    btn_accept, btn_discard, btn_chk = st.columns([2, 1.5, 1.5])
                    with btn_accept:
                        if st.button(f"âœ… æ›¿æ¢ä¸º AI ç‰ˆæœ¬", key=f"accept_{fpath}",
                                     type="primary", use_container_width=True):
                            proj_now.set_script(stype, diffs.pop(fpath))
                            st.rerun()
                    with btn_discard:
                        if st.button(f"âŒ ä¸¢å¼ƒ AI å»ºè®®", key=f"discard_{fpath}",
                                     use_container_width=True):
                            diffs.pop(fpath)
                            st.rerun()
                    with btn_chk:
                        if st.button(f"ğŸ” æ£€æŸ¥ AI", key=f"chk_ai_{fpath}",
                                     use_container_width=True):
                            for iss in check_gdl_script(diffs.get(fpath, ""), skey):
                                if iss.startswith("âœ…"):
                                    st.success(iss)
                                else:
                                    st.warning(iss)

                else:
                    # â”€â”€ Normal single editor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                    new_code = st.text_area(
                        label, value=current_code, height=380,
                        key=f"script_{fpath}", label_visibility="collapsed",
                    )
                    if new_code != current_code:
                        proj_now.set_script(stype, new_code)

                    if st.button(f"ğŸ” æ£€æŸ¥", key=f"chk_{fpath}"):
                        for iss in check_gdl_script(new_code, skey):
                            if iss.startswith("âœ…"):
                                st.success(iss)
                            else:
                                st.warning(iss)

        # â”€â”€ æ—¥å¿— Tab â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with tab_log:
            if not st.session_state.compile_log:
                st.info("æš‚æ— ç¼–è¯‘è®°å½•")
            else:
                for entry in reversed(st.session_state.compile_log):
                    icon = "âœ…" if entry["success"] else "âŒ"
                    st.markdown(f"**{icon} {entry['project']}** â€” {entry.get('instruction','')}")
                    st.code(entry["message"], language="text")
                    st.divider()
            if st.button("æ¸…é™¤æ—¥å¿—"):
                st.session_state.compile_log = []
                st.rerun()

            with st.expander("HSF ç›®å½•ç»“æ„"):
                tree = [f"ğŸ“ {proj_now.name}/", "  â”œâ”€â”€ libpartdata.xml",
                        "  â”œâ”€â”€ paramlist.xml", "  â”œâ”€â”€ ancestry.xml", "  â””â”€â”€ scripts/"]
                for stype in ScriptType:
                    if stype in proj_now.scripts:
                        n = proj_now.scripts[stype].count("\n") + 1
                        tree.append(f"       â”œâ”€â”€ {stype.value} ({n} lines)")
                st.code("\n".join(tree), language="text")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Chat Input â€” Always at Bottom
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

user_input = st.chat_input(
    "æè¿°ä½ æƒ³åˆ›å»ºæˆ–ä¿®æ”¹çš„ GDL å¯¹è±¡ï¼Œå¦‚ã€Œåˆ›å»ºä¸€ä¸ªå®½ 600mm çš„ä¹¦æ¶ï¼ŒiShelves æ§åˆ¶å±‚æ•°ã€"
)

if user_input:
    # Add user message to history
    st.session_state.chat_history.append({"role": "user", "content": user_input})

    # Check API key first
    if not api_key and "ollama" not in model_name:
        err = "âŒ è¯·åœ¨å·¦ä¾§è¾¹æ å¡«å…¥ API Key åå†è¯•ã€‚"
        st.session_state.chat_history.append({"role": "assistant", "content": err})
        st.rerun()
    else:
        llm_for_classify = get_llm()

        # â”€â”€ Intent + Name in ONE call â”€â”€
        intent, gdl_obj_name = classify_and_extract(user_input, llm_for_classify)

        with live_output.container():
            st.chat_message("user").markdown(user_input)
            with st.chat_message("assistant"):
                if intent == "CHAT":
                    # â”€â”€ Casual conversation â€” no project creation, no agent â”€â”€
                    msg = chat_respond(
                        user_input,
                        st.session_state.chat_history[:-1],
                        llm_for_classify,
                    )
                    st.markdown(msg)

                else:
                    # â”€â”€ GDL intent â€” create project if needed, then run agent â”€â”€
                    if not st.session_state.project:
                        new_proj = HSFProject.create_new(gdl_obj_name, work_dir=st.session_state.work_dir)
                        st.session_state.project = new_proj
                        st.session_state.pending_gsm_name = gdl_obj_name
                        st.info(f"ğŸ“ å·²åˆå§‹åŒ–é¡¹ç›® `{gdl_obj_name}`")

                    proj_current = st.session_state.project
                    # Keep existing gsm_name if project already loaded
                    effective_gsm = (
                        st.session_state.pending_gsm_name
                        or proj_current.name
                    )
                    msg = run_agent_generate(user_input, proj_current, st.container(), gsm_name=effective_gsm)
                    st.markdown(msg)

        st.session_state.chat_history.append({"role": "assistant", "content": msg})
        st.rerun()


# â”€â”€ Footer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.divider()
st.markdown(
    '<p style="text-align:center; color:#64748b; font-size:0.8rem;">'
    'gdl-agent v0.5.0 Â· HSF-native Â·'
    '<a href="https://github.com/byewind/gdl-agent">GitHub</a>'
    '</p>',
    unsafe_allow_html=True,
)
