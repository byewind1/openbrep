"""
gdl-agent Web UI â€” Streamlit interface for architects.

Run: streamlit run ui/app.py
"""

import sys
import re
import os
import time
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

import streamlit as st

from gdl_agent.hsf_project import HSFProject, ScriptType, GDLParameter
from gdl_agent.gdl_parser import parse_gdl_source, parse_gdl_file
from gdl_agent.paramlist_builder import build_paramlist_xml, validate_paramlist
from gdl_agent.compiler import MockHSFCompiler, HSFCompiler, CompileResult
from gdl_agent.core import GDLAgent, Status
from gdl_agent.knowledge import KnowledgeBase
from gdl_agent.skills_loader import SkillsLoader


# â”€â”€ Page Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(
    page_title="gdl-agent",
    page_icon="ğŸ—ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â”€â”€ Custom CSS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;600&family=Noto+Sans+SC:wght@300;400;600&display=swap');

.stApp { font-family: 'Noto Sans SC', sans-serif; }
code, .stCodeBlock { font-family: 'JetBrains Mono', monospace !important; }

.main-header {
    font-family: 'JetBrains Mono', monospace;
    font-size: 2rem; font-weight: 600;
    background: linear-gradient(135deg, #22d3ee, #34d399);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    margin-bottom: 0;
}
.sub-header { color: #94a3b8; font-size: 0.9rem; margin-top: -0.5rem; margin-bottom: 2rem; }

.welcome-card {
    background: linear-gradient(135deg, #0f172a, #1e293b);
    border: 1px solid #334155;
    border-radius: 12px;
    padding: 2rem;
    margin: 1rem 0;
}
.step-item {
    display: flex;
    align-items: flex-start;
    gap: 0.75rem;
    margin-bottom: 1rem;
    padding: 0.75rem;
    background: #1e293b;
    border-radius: 8px;
    border-left: 3px solid #22d3ee;
}
.diff-current { border-left: 3px solid #475569; padding-left: 0.5rem; }
.diff-ai      { border-left: 3px solid #f59e0b; padding-left: 0.5rem; }
.diff-badge {
    display: inline-block;
    background: #f59e0b22;
    color: #f59e0b;
    border: 1px solid #f59e0b55;
    border-radius: 4px;
    padding: 2px 8px;
    font-size: 0.78rem;
    font-family: 'JetBrains Mono', monospace;
    margin-bottom: 4px;
}
</style>
""", unsafe_allow_html=True)


# â”€â”€ Session State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if "project" not in st.session_state:
    st.session_state.project = None
if "compile_log" not in st.session_state:
    st.session_state.compile_log = []
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "work_dir" not in st.session_state:
    st.session_state.work_dir = str(Path.home() / "gdl-agent-workspace")
if "agent_running" not in st.session_state:
    st.session_state.agent_running = False
if "pending_diffs" not in st.session_state:
    # AI-proposed changes awaiting user review. {script_path: new_content}
    # e.g. {"scripts/3d.gdl": "...", "scripts/2d.gdl": "..."}
    st.session_state.pending_diffs = {}
if "pending_gsm_name" not in st.session_state:
    st.session_state.pending_gsm_name = ""
if "confirm_clear" not in st.session_state:
    st.session_state.confirm_clear = False
if "model_api_keys" not in st.session_state:
    # Per-model API Key storage â€” pre-fill from config.toml provider_keys
    st.session_state.model_api_keys = {}


# â”€â”€ Load config.toml defaults â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_config_defaults = {}
_provider_keys: dict = {}   # {provider: api_key}

try:
    from gdl_agent.config import GDLAgentConfig
    import sys as _sys, os as _os
    # Load raw TOML to get provider_keys nested table
    if _sys.version_info >= (3, 11):
        import tomllib as _tomllib
    else:
        import tomli as _tomllib   # type: ignore

    _toml_path = _os.path.join(_os.path.dirname(__file__), "..", "config.toml")
    if _os.path.exists(_toml_path):
        with open(_toml_path, "rb") as _f:
            _raw = _tomllib.load(_f)
        _provider_keys = _raw.get("llm", {}).get("provider_keys", {})

    _config = GDLAgentConfig.load()
    _config_defaults = {
        "llm_model": _config.llm.model,
        "compiler_path": _config.compiler.path or "",
    }
except Exception:
    pass


def _key_for_model(model: str) -> str:
    """Pick the right API Key from provider_keys based on model name."""
    m = model.lower()
    if "glm" in m:
        return _provider_keys.get("zhipu", "")
    elif "deepseek" in m and "ollama" not in m:
        return _provider_keys.get("deepseek", "")
    elif "claude" in m:
        return _provider_keys.get("anthropic", "")
    elif "gpt" in m or "o3" in m or "o1" in m:
        return _provider_keys.get("openai", "")
    elif "gemini" in m:
        return _provider_keys.get("google", "")
    return ""

# â”€â”€ Sidebar Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with st.sidebar:
    st.markdown('<p class="main-header">gdl-agent</p>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">v0.5.0 Â· HSF-native Â· AI-powered</p>', unsafe_allow_html=True)
    st.divider()

    st.subheader("ğŸ“ å·¥ä½œç›®å½•")
    work_dir = st.text_input("Work Directory", value=st.session_state.work_dir, label_visibility="collapsed")
    st.session_state.work_dir = work_dir

    st.divider()
    st.subheader("ğŸ”§ ç¼–è¯‘å™¨ / Compiler")

    compiler_mode = st.radio(
        "ç¼–è¯‘æ¨¡å¼",
        ["Mock (æ— éœ€ ArchiCAD)", "LP_XMLConverter (çœŸå®ç¼–è¯‘)"],
        index=1 if _config_defaults.get("compiler_path") else 0,
    )

    converter_path = ""
    if compiler_mode.startswith("LP"):
        converter_path = st.text_input(
            "LP_XMLConverter è·¯å¾„",
            value=_config_defaults.get("compiler_path", ""),
            placeholder="/Applications/GRAPHISOFT/ArchiCAD 28/LP_XMLConverter",
        )

    st.divider()
    st.subheader("ğŸ§  AI æ¨¡å‹ / LLM")

    model_options = [
        # â”€â”€ Anthropic Claude â”€â”€
        "claude-haiku-4-5-20251001",
        "claude-sonnet-4-5-20250929",
        "claude-opus-4-5-20250918",
        "claude-opus-4-6",
        # â”€â”€ æ™ºè°± GLM (Z.ai) â”€â”€
        "glm-4.7",
        "glm-4.7-flash",
        "glm-4-plus",
        "glm-4-flash",
        # â”€â”€ OpenAI â”€â”€
        "gpt-4o",
        "gpt-4o-mini",
        "o3-mini",
        # â”€â”€ DeepSeek â”€â”€
        "deepseek-chat",
        "deepseek-reasoner",
        # â”€â”€ Google Gemini â”€â”€
        "gemini/gemini-2.5-flash",
        "gemini/gemini-2.5-pro",
        # â”€â”€ Ollama æœ¬åœ° â”€â”€
        "ollama/qwen2.5:14b",
        "ollama/qwen3:8b",
        "ollama/deepseek-coder-v2:16b",
    ]

    default_model = _config_defaults.get("llm_model", "glm-4.7")
    default_index = model_options.index(default_model) if default_model in model_options else 4

    model_name = st.selectbox("æ¨¡å‹ / Model", model_options, index=default_index)

    # Load or initialize API Key for this specific model
    if model_name not in st.session_state.model_api_keys:
        # Auto-fill from config.toml provider_keys
        st.session_state.model_api_keys[model_name] = _key_for_model(model_name)

    api_key = st.text_input(
        "API Key",
        value=st.session_state.model_api_keys.get(model_name, ""),
        type="password",
        help="Ollama æœ¬åœ°æ¨¡å¼ä¸éœ€è¦ Key"
    )

    # Auto-save API Key if user manually edited it
    if api_key != st.session_state.model_api_keys.get(model_name, ""):
        st.session_state.model_api_keys[model_name] = api_key

    if "claude" in model_name:
        st.caption("ğŸ”‘ [è·å– Claude API Key â†’](https://console.anthropic.com/settings/keys)")
        st.caption("âš ï¸ API Key éœ€å•ç‹¬å……å€¼ï¼Œä¸ Claude Pro è®¢é˜…é¢åº¦æ— å…³")
    elif "glm" in model_name:
        st.caption("ğŸ”‘ [è·å–æ™ºè°± API Key â†’](https://bigmodel.cn/usercenter/apikeys)")
    elif "gpt" in model_name or "o3" in model_name:
        st.caption("ğŸ”‘ [è·å– OpenAI API Key â†’](https://platform.openai.com/api-keys)")
    elif "deepseek" in model_name and "ollama" not in model_name:
        st.caption("ğŸ”‘ [è·å– DeepSeek API Key â†’](https://platform.deepseek.com/api_keys)")
    elif "gemini" in model_name:
        st.caption("ğŸ”‘ [è·å– Gemini API Key â†’](https://aistudio.google.com/apikey)")
    elif "ollama" in model_name:
        st.caption("ğŸ–¥ï¸ æœ¬åœ°è¿è¡Œï¼Œæ— éœ€ Keyã€‚ç¡®ä¿ Ollama å·²å¯åŠ¨ã€‚")

    # API Base URL â€” only needed for OpenAI-compatible custom endpoints
    # zai/ (GLM), deepseek/, anthropic/ are native LiteLLM providers, no api_base needed
    def _get_default_api_base(model: str) -> str:
        m = model.lower()
        if "ollama" in m:
            return "http://localhost:11434"
        # GLM uses zai/ native provider â€” no api_base
        # DeepSeek uses deepseek/ native provider â€” no api_base
        return ""

    default_api_base = _get_default_api_base(model_name)
    api_base = ""
    if default_api_base:
        api_base = st.text_input("API Base URL", value=default_api_base)

    max_retries = st.slider("æœ€å¤§é‡è¯•æ¬¡æ•°", 1, 10, 5)

    st.divider()

    # Project info + quick reset
    if st.session_state.project:
        proj = st.session_state.project
        st.subheader(f"ğŸ“¦ {proj.name}")
        st.caption(f"å‚æ•°: {len(proj.parameters)} | è„šæœ¬: {len(proj.scripts)}")
        if st.button("ğŸ—‘ï¸ æ¸…é™¤é¡¹ç›®", use_container_width=True):
            st.session_state.project = None
            st.session_state.chat_history = []
            st.rerun()


# â”€â”€ Helper Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_compiler():
    if compiler_mode.startswith("Mock"):
        return MockHSFCompiler()
    return HSFCompiler(converter_path or None)

def get_llm():
    from gdl_agent.config import LLMConfig
    from gdl_agent.llm import LLMAdapter
    config = LLMConfig(
        model=model_name,
        api_key=api_key,
        api_base=api_base,
        temperature=0.2,
        max_tokens=4096,
    )
    return LLMAdapter(config)

def load_knowledge(task_type: str = "all"):
    # Always load from project knowledge dir first (contains pro ccgdl_dev_doc)
    project_kb = Path(__file__).parent.parent / "knowledge"
    kb = KnowledgeBase(str(project_kb))
    kb.load()

    # Merge user's custom knowledge from work_dir (if different & exists)
    user_kb_dir = Path(st.session_state.work_dir) / "knowledge"
    if user_kb_dir.exists() and user_kb_dir != project_kb:
        user_kb = KnowledgeBase(str(user_kb_dir))
        user_kb.load()
        kb._docs.update(user_kb._docs)   # user custom overrides project

    return kb.get_by_task_type(task_type)

def load_skills():
    # Always load from project skills dir first
    project_sk = Path(__file__).parent.parent / "skills"
    sl = SkillsLoader(str(project_sk))
    sl.load()

    # Merge user's custom skills from work_dir
    user_sk_dir = Path(st.session_state.work_dir) / "skills"
    if user_sk_dir.exists() and user_sk_dir != project_sk:
        user_sl = SkillsLoader(str(user_sk_dir))
        user_sl.load()
        sl._skills.update(user_sl._skills)   # user custom overrides project

    return sl

def _versioned_gsm_path(proj_name: str, work_dir: str) -> str:
    """
    Return next available versioned GSM path.
    MyShelf_v1.gsm â†’ MyShelf_v2.gsm â†’ ...
    Preserves all previous compilations.
    """
    out_dir = Path(work_dir) / "output"
    out_dir.mkdir(parents=True, exist_ok=True)
    v = 1
    while (out_dir / f"{proj_name}_v{v}.gsm").exists():
        v += 1
    return str(out_dir / f"{proj_name}_v{v}.gsm")


# â”€â”€ Object Name Extraction (dictionary + regex, no LLM) â”€â”€

_CN_TO_NAME = {
    # å®¶å…·
    "ä¹¦æ¶": "Bookshelf", "ä¹¦æŸœ": "Bookcase", "æŸœå­": "Cabinet",
    "è¡£æŸœ": "Wardrobe", "æ©±æŸœ": "Kitchen Cabinet", "å‚¨ç‰©æŸœ": "StorageUnit",
    "æ¡Œå­": "Table", "æ¡Œ": "Table", "ä¹¦æ¡Œ": "Desk", "é¤æ¡Œ": "DiningTable",
    "æ¤…å­": "Chair", "æ¤…": "Chair", "æ²™å‘": "Sofa", "åºŠ": "Bed",
    "èŒ¶å‡ ": "CoffeeTable", "ç”µè§†æŸœ": "TVStand", "é‹æŸœ": "ShoeRack",
    # å»ºç­‘æ„ä»¶
    "çª—": "Window", "çª—æ¡†": "WindowFrame", "çª—æˆ·": "Window", "ç™¾å¶çª—": "Louver",
    "é—¨": "Door", "é—¨æ¡†": "DoorFrame", "æ¨æ‹‰é—¨": "SlidingDoor", "æ—‹è½¬é—¨": "RevolvingDoor",
    "å¢™": "Wall", "å¢™æ¿": "WallPanel", "éš”å¢™": "Partition", "å¹•å¢™": "CurtainWall",
    "æ¥¼æ¢¯": "Staircase", "å°é˜¶": "StairStep", "æ‰¶æ‰‹": "Handrail", "æ æ†": "Railing",
    "æŸ±": "Column", "æŸ±å­": "Column", "æ¢": "Beam", "æ¿": "Slab",
    "å±‹é¡¶": "Roof", "å¤©èŠ±": "Ceiling", "åœ°æ¿": "Floor",
    # è®¾å¤‡
    "ç¯": "Light", "ç¯å…·": "LightFixture", "ç®¡é“": "Pipe", "é£ç®¡": "Duct",
    "å¼€å…³": "Switch", "æ’åº§": "Outlet", "ç©ºè°ƒ": "AirConditioner",
    # æ™¯è§‚
    "èŠ±ç›†": "Planter", "æ ‘": "Tree", "å›´æ ": "Fence", "é•¿å‡³": "Bench",
}

def _extract_object_name(text: str) -> str:
    """
    Extract GDL object name from user input.
    Priority: explicit English name > Chinese keyword dict > fallback.
    Zero LLM calls â€” instant and 100% reliable.
    """
    # 1. Check for explicit English name: "named MyShelf", "å« MyShelf"
    for pat in [
        r'named?\s+([A-Za-z][A-Za-z0-9]{2,30})',
        r'called\s+([A-Za-z][A-Za-z0-9]{2,30})',
        r'åä¸º\s*([A-Za-z][A-Za-z0-9]{2,30})',
        r'å«\s*([A-Za-z][A-Za-z0-9]{2,30})',
    ]:
        m = re.search(pat, text, re.IGNORECASE)
        if m:
            return m.group(1)

    # 2. Chinese keyword â†’ English CamelCase (longest match first)
    for cn, en in sorted(_CN_TO_NAME.items(), key=lambda x: len(x[0]), reverse=True):
        if cn in text:
            print(f"[name] '{cn}' â†’ {en}")
            return en

    # 3. Pick first CamelCase English word in text (skip short junk like UI, AI, GDL)
    for word in re.findall(r'[A-Z][a-z]{2,}[A-Za-z0-9]*', text):
        if word not in {"The", "For", "And", "Not", "But", "With"}:
            return word

    return "MyObject"


# â”€â”€ Welcome / Onboarding Panel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def show_welcome():
    st.markdown("""
<div class="welcome-card">
<h2 style="color:#22d3ee; margin-top:0; font-family:'JetBrains Mono';">æ¬¢è¿ä½¿ç”¨ gdl-agent ğŸ—ï¸</h2>
<p style="color:#94a3b8;">ç”¨è‡ªç„¶è¯­è¨€é©±åŠ¨ ArchiCAD GDL å¯¹è±¡çš„åˆ›å»ºä¸ç¼–è¯‘ã€‚æ— éœ€äº†è§£ GDL è¯­æ³•ï¼Œç›´æ¥æè¿°éœ€æ±‚å³å¯ã€‚</p>
</div>
""", unsafe_allow_html=True)

    st.markdown("#### ä¸‰æ­¥å¿«é€Ÿå¼€å§‹")

    st.info("**â‘  é…ç½® API Key**  \nåœ¨å·¦ä¾§è¾¹æ é€‰æ‹© AI æ¨¡å‹ï¼Œå¡«å…¥å¯¹åº” API Keyã€‚å…è´¹çš„æ™ºè°± GLM å¯ç›´æ¥ä½¿ç”¨ã€‚")
    st.info("**â‘¡ å¼€å§‹å¯¹è¯**  \nåœ¨åº•éƒ¨è¾“å…¥æ¡†æè¿°ä½ æƒ³åˆ›å»ºçš„ GDL å¯¹è±¡ï¼Œä¾‹å¦‚ï¼š  \nã€Œåˆ›å»ºä¸€ä¸ªå®½ 600mmã€æ·± 400mm çš„ä¹¦æ¶ï¼Œå¸¦ iShelves å‚æ•°æ§åˆ¶å±‚æ•°ã€")
    st.info("**â‘¢ ç¼–è¯‘è¾“å‡º**  \nAI ç”Ÿæˆä»£ç åè‡ªåŠ¨è§¦å‘ç¼–è¯‘ã€‚çœŸå®ç¼–è¯‘éœ€åœ¨ä¾§è¾¹æ é…ç½® LP_XMLConverter è·¯å¾„ã€‚Mock æ¨¡å¼å¯éªŒè¯ç»“æ„ï¼Œæ— éœ€å®‰è£… ArchiCADã€‚")

    st.divider()

    st.markdown("#### æˆ–è€…ï¼šå¯¼å…¥å·²æœ‰ GDL æ–‡ä»¶")
    uploaded_file = st.file_uploader(
        "æ‹–å…¥ .gdl æ–‡ä»¶å¼€å§‹ç¼–è¾‘",
        type=["gdl", "txt"],
        help="æ”¯æŒ AI ç”Ÿæˆæˆ–æ‰‹å†™çš„ GDL æºç ",
        key="welcome_upload",
    )
    if uploaded_file:
        content = uploaded_file.read().decode("utf-8", errors="replace")
        name = Path(uploaded_file.name).stem
        try:
            project = parse_gdl_source(content, name)
            project.work_dir = Path(st.session_state.work_dir)
            project.root = project.work_dir / project.name
            st.session_state.project = project
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": f"âœ… å·²å¯¼å…¥ `{project.name}` â€” {len(project.parameters)} ä¸ªå‚æ•°ï¼Œ{len(project.scripts)} ä¸ªè„šæœ¬ã€‚å¯ä»¥å¼€å§‹å¯¹è¯ä¿®æ”¹äº†ã€‚"
            })
            st.rerun()
        except Exception as e:
            st.error(f"âŒ å¯¼å…¥å¤±è´¥: {e}")

    st.divider()
    st.caption("ğŸ’¡ æç¤ºï¼šç¬¬ä¸€æ¡æ¶ˆæ¯æ— éœ€åˆ›å»ºé¡¹ç›®ï¼Œç›´æ¥æè¿°éœ€æ±‚ï¼ŒAI ä¼šè‡ªåŠ¨åˆå§‹åŒ–ã€‚")


# â”€â”€ Intent Classification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_GDL_KEYWORDS = [
    # åŠ¨ä½œ
    "åˆ›å»º", "ç”Ÿæˆ", "åˆ¶ä½œ", "åšä¸€ä¸ª", "å»ºä¸€ä¸ª", "å†™ä¸€ä¸ª", "å†™ä¸ª", "å†™ä¸€",
    "åšä¸ª", "å»ºä¸ª", "æ¥ä¸ª", "æ•´ä¸ª", "å‡ºä¸€ä¸ª", "å‡ºä¸ª",
    "ä¿®æ”¹", "æ›´æ–°", "æ·»åŠ ", "åˆ é™¤", "è°ƒæ•´", "ä¼˜åŒ–", "é‡å†™", "è¡¥å……",
    # å»ºç­‘/å®¶å…·å¯¹è±¡ï¼ˆä¸­æ–‡ï¼‰
    "ä¹¦æ¶", "æŸœå­", "è¡£æŸœ", "æ©±æŸœ", "å‚¨ç‰©æŸœ", "é‹æŸœ", "ç”µè§†æŸœ",
    "æ¡Œå­", "æ¡Œ", "æ¤…å­", "æ¤…", "æ²™å‘", "åºŠ", "èŒ¶å‡ ", "æŸœ",
    "çª—", "é—¨", "å¢™", "æ¥¼æ¢¯", "æŸ±", "æ¢", "æ¿", "æ‰¶æ‰‹", "æ æ†",
    "å±‹é¡¶", "å¤©èŠ±", "åœ°æ¿", "ç¯", "ç®¡é“",
    # æŠ€æœ¯è¯
    "å‚æ•°", "parameter", "script", "gdl", "gsm", "hsf",
    "compile", "ç¼–è¯‘", "build", "create", "make", "add",
    "3d", "2d", "prism", "block", "sphere", "prism_", "body",
    "project2", "rect2", "poly2",
]

# Pure chat patterns â€” greeting / meta questions only
_CHAT_ONLY_PATTERNS = [
    r"^(ä½ å¥½|hello|hi|hey|å—¨|å“ˆå–½)[!ï¼ã€‚\s]*$",
    r"^(è°¢è°¢|æ„Ÿè°¢|thanks)[!ï¼ã€‚\s]*$",
    r"^ä½ (æ˜¯è°|èƒ½åšä»€ä¹ˆ|æœ‰ä»€ä¹ˆåŠŸèƒ½)",
    r"^(æ€ä¹ˆ|å¦‚ä½•|ä»€ä¹ˆæ˜¯).*(gdl|archicad|hsf|æ„ä»¶)",
]

def _is_gdl_intent(text: str) -> bool:
    t = text.lower()
    return any(kw in t for kw in _GDL_KEYWORDS)

def _is_pure_chat(text: str) -> bool:
    return any(re.search(p, text.strip(), re.IGNORECASE) for p in _CHAT_ONLY_PATTERNS)

def classify_and_extract(text: str, llm, project_loaded: bool = False) -> tuple:
    """
    Returns: (intent, obj_name)
    When project is already loaded, default to GDL for anything ambiguous.
    """
    obj_name = _extract_object_name(text)

    # Pure greetings / meta questions always â†’ CHAT regardless of project state
    if _is_pure_chat(text):
        return ("CHAT", obj_name)

    # Keyword fast-path
    if _is_gdl_intent(text):
        return ("GDL", obj_name)

    # Project loaded: assume user wants to edit â€” treat ambiguous as GDL
    if project_loaded:
        print(f"[classify] project loaded â†’ default GDL for: '{text[:40]}'")
        return ("GDL", obj_name)

    # No project, ambiguous â†’ ask LLM (one word)
    try:
        resp = llm.generate([
            {
                "role": "system",
                "content": (
                    "ä½ æ˜¯æ„å›¾åˆ†ç±»å™¨ã€‚åˆ¤æ–­ç”¨æˆ·æ˜¯å¦æƒ³åˆ›å»ºæˆ–ä¿®æ”¹ ArchiCAD GDL æ„ä»¶ã€‚\n"
                    "åªå›å¤ä¸€ä¸ªè¯ï¼šGDL æˆ– CHAT\n"
                    "GDL = è¦åˆ›å»º/ä¿®æ”¹/ç¼–è¯‘æ„ä»¶\n"
                    "CHAT = é—²èŠ/æ‰“æ‹›å‘¼/é—®ç”¨æ³•"
                ),
            },
            {"role": "user", "content": text},
        ], max_tokens=10, temperature=0.1)

        raw = resp.content.strip().upper()
        print(f"[classify] LLM intent: '{raw}'")
        return ("GDL" if "GDL" in raw else "CHAT", obj_name)

    except Exception as e:
        print(f"[classify] exception: {e}")
        return ("CHAT", obj_name)


def chat_respond(user_input: str, history: list, llm) -> str:
    """Simple conversational response. Never outputs GDL code â€” that goes to the editor."""
    system_msg = {
        "role": "system",
        "content": (
            "ä½ æ˜¯ gdl-agent çš„å†…ç½®åŠ©æ‰‹ï¼Œä¸“æ³¨äº ArchiCAD GDL å¯¹è±¡ç¼–è¾‘å™¨çš„ä½¿ç”¨æŒ‡å¼•ã€‚\n"
            "ã€é‡è¦çº¦æŸã€‘ç»å¯¹ç¦æ­¢åœ¨å›å¤ä¸­è¾“å‡ºä»»ä½• GDL ä»£ç ã€ä»£ç å—æˆ–è„šæœ¬ç‰‡æ®µã€‚"
            "å¦‚æœç”¨æˆ·æƒ³åˆ›å»ºæˆ–ä¿®æ”¹ GDL å¯¹è±¡ï¼Œå‘Šè¯‰ä»–ã€Œç›´æ¥åœ¨åº•éƒ¨è¾“å…¥æ¡†æè¿°éœ€æ±‚ï¼ŒAI ä¼šè‡ªåŠ¨ç”Ÿæˆå¹¶å¡«å…¥ç¼–è¾‘å™¨ã€ã€‚\n"
            "ä¸è¦æåŠ ArchiCAD å†…éƒ¨æ“ä½œï¼ˆå¦‚æ‰“å¼€ GDL å¯¹è±¡ç¼–è¾‘å™¨ï¼‰ï¼Œå› ä¸ºæœ¬å·¥å…·å°±æ˜¯ä½“å¤–çš„ GDL IDEã€‚\n"
            "å›å¤ç®€æ´ï¼Œä½¿ç”¨ä¸­æ–‡ï¼Œä¸“ä¸šæœ¯è¯­ä¿ç•™è‹±æ–‡ï¼ˆGDLã€HSFã€GSMã€paramlist ç­‰ï¼‰ã€‚"
        ),
    }
    messages = [system_msg]
    # Include recent history for context (last 6 messages)
    for msg in history[-6:]:
        messages.append({"role": msg["role"], "content": msg["content"]})
    messages.append({"role": "user", "content": user_input})

    try:
        resp = llm.generate(messages)
        return resp.content
    except Exception as e:
        return f"âŒ {str(e)}"


# â”€â”€ Script Map (module-level, shared by agent + editor) â”€â”€â”€
_SCRIPT_MAP = [
    (ScriptType.SCRIPT_3D, "scripts/3d.gdl",  "3D"),
    (ScriptType.SCRIPT_2D, "scripts/2d.gdl",  "2D"),
    (ScriptType.MASTER,    "scripts/1d.gdl",  "Master"),
    (ScriptType.PARAM,     "scripts/vl.gdl",  "Param"),
    (ScriptType.UI,        "scripts/ui.gdl",  "UI"),
    (ScriptType.PROPERTIES,"scripts/pr.gdl",  "Properties"),
]

# â”€â”€ Run Agent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_agent_generate(user_input: str, proj: HSFProject, status_col, gsm_name: str = None) -> str:
    """
    Generate code only (no compile).
    Directly applies AI output to project scripts â€” no confirmation needed.
    """
    status_ph = status_col.empty()

    def on_event(event_type, data):
        if event_type == "analyze":
            scripts = data.get("affected_scripts", [])
            status_ph.info(f"ğŸ” åˆ†æä¸­... å½±å“è„šæœ¬: {', '.join(scripts)}")
        elif event_type == "attempt":
            status_ph.info("ğŸ§  è°ƒç”¨ AI ç”Ÿæˆä»£ç ...")
        elif event_type == "llm_response":
            status_ph.info(f"âœï¸ æ”¶åˆ° {data['length']} å­—ç¬¦ï¼Œè§£æä¸­...")

    try:
        llm = get_llm()
        knowledge = load_knowledge()
        skills_text = load_skills().get_for_task(user_input)

        agent = GDLAgent(llm=llm, compiler=get_compiler(), on_event=on_event)
        changes = agent.generate_only(
            instruction=user_input, project=proj,
            knowledge=knowledge, skills=skills_text,
        )
        status_ph.empty()

        if not changes:
            return "âŒ AI è¾“å‡ºæ— æ³•è§£æï¼Œè¯·é‡æ–°æè¿°éœ€æ±‚ã€‚"

        # Strip markdown fences, then directly apply to project scripts
        cleaned = {k: _strip_md_fences(v) for k, v in changes.items()}
        _apply_scripts_to_project(proj, cleaned)
        if gsm_name:
            st.session_state.pending_gsm_name = gsm_name

        script_names = ", ".join(
            p.replace("scripts/", "").replace(".gdl", "").upper()
            for p in cleaned.keys()
            if p.startswith("scripts/")
        )
        return f"âœï¸ **AI å·²å†™å…¥è„šæœ¬** [{script_names}]ï¼Œç‚¹å‡»ã€ŒğŸ”§ ç¼–è¯‘ã€å³å¯ã€‚"

    except Exception as e:
        status_ph.empty()
        return f"âŒ **é”™è¯¯**: {str(e)}"


def _apply_scripts_to_project(proj: HSFProject, script_map: dict) -> None:
    """Apply a {fpath: content} dict directly to project via set_script."""
    for stype, fpath, _label in _SCRIPT_MAP:
        if fpath in script_map:
            proj.set_script(stype, script_map[fpath])


def do_compile(proj: HSFProject, gsm_name: str, instruction: str = "") -> tuple:
    """
    Compile current project state â†’ versioned GSM.
    Returns (success: bool, message: str).
    """
    try:
        output_gsm = _versioned_gsm_path(gsm_name or proj.name, st.session_state.work_dir)
        hsf_dir = proj.save_to_disk()
        result = get_compiler().hsf2libpart(str(hsf_dir), output_gsm)
        mock_tag = " [Mock]" if compiler_mode.startswith("Mock") else ""

        if result.success:
            st.session_state.compile_log.append({
                "project": proj.name, "instruction": instruction,
                "success": True, "attempts": 1, "message": "Success",
            })
            msg = f"âœ… **ç¼–è¯‘æˆåŠŸ{mock_tag}**\n\nğŸ“¦ `{output_gsm}`"
            if compiler_mode.startswith("Mock"):
                msg += "\n\nâš ï¸ Mock æ¨¡å¼ä¸ç”ŸæˆçœŸå® .gsmï¼Œåˆ‡æ¢ LP_XMLConverter è¿›è¡ŒçœŸå®ç¼–è¯‘ã€‚"
            return (True, msg)
        else:
            st.session_state.compile_log.append({
                "project": proj.name, "instruction": instruction,
                "success": False, "attempts": 1, "message": result.stderr,
            })
            return (False, f"âŒ **ç¼–è¯‘å¤±è´¥**\n\n```\n{result.stderr[:500]}\n```")
    except Exception as e:
        return (False, f"âŒ **é”™è¯¯**: {str(e)}")


def import_gsm(gsm_bytes: bytes, filename: str) -> tuple:
    """
    Decompile GSM â†’ HSF â†’ HSFProject.
    Returns (project | None, message).
    """
    import tempfile, shutil
    tmp = Path(tempfile.mkdtemp())
    gsm_path = tmp / filename
    gsm_path.write_bytes(gsm_bytes)
    hsf_out = tmp / "hsf_out"
    hsf_out.mkdir()
    result = get_compiler().libpart2hsf(str(gsm_path), str(hsf_out))
    if not result.success:
        shutil.rmtree(tmp, ignore_errors=True)
        return (None, f"âŒ GSM è§£åŒ…å¤±è´¥: {result.stderr}")
    try:
        # LP_XMLConverter creates a subdirectory named after the object
        subdirs = [d for d in hsf_out.iterdir() if d.is_dir()]
        hsf_dir = subdirs[0] if subdirs else hsf_out
        proj = HSFProject.from_hsf(str(hsf_dir))
        proj.work_dir = Path(st.session_state.work_dir)
        proj.root = proj.work_dir / proj.name
        return (proj, f"âœ… å·²å¯¼å…¥ `{proj.name}` â€” {len(proj.parameters)} å‚æ•°ï¼Œ{len(proj.scripts)} è„šæœ¬")
    except Exception as e:
        return (None, f"âŒ HSF è§£æå¤±è´¥: {e}")
    finally:
        shutil.rmtree(tmp, ignore_errors=True)


def _strip_md_fences(code: str) -> str:
    """Remove markdown code fences (```gdl / ```) that AI sometimes leaks into scripts."""
    import re as _re
    # Remove opening fence (```gdl, ```GDL, ```)
    code = _re.sub(r'^```[a-zA-Z]*\s*\n?', '', code.strip(), flags=_re.MULTILINE)
    # Remove closing fence
    code = _re.sub(r'\n?```\s*$', '', code.strip(), flags=_re.MULTILINE)
    return code.strip()


def _extract_gdl_from_chat() -> dict:
    """
    Scan chat history for fenced code blocks containing GDL.
    Returns {script_path: content} ready to merge into pending_diffs.
    Heuristic type detection: 3D (has BODY/PRISM_/END), 2D (has PROJECT2),
    Master (has GLOB_ / PARAMETERS keyword), Param (has PARAMETERS section).
    Multiple blocks â†’ last block wins per type.
    """
    import re as _re
    collected: dict[str, str] = {}
    code_block_pat = _re.compile(r"```(?:gdl|GDL)?\s*\n(.*?)```", _re.DOTALL)

    for msg in st.session_state.get("chat_history", []):
        if msg.get("role") != "assistant":
            continue
        content = msg.get("content", "")
        for m in code_block_pat.finditer(content):
            block = m.group(1).strip()
            if not block:
                continue
            # Classify by content heuristics
            block_up = block.upper()
            if _re.search(r'\bPROJECT2\b|\bRECT2\b|\bPOLY2\b', block_up):
                path = "scripts/2d.gdl"
            elif _re.search(r'\bPARAMETERS\b', block_up):
                path = "scripts/vl.gdl"
            elif _re.search(r'\bGLOB_\w+\b', block_up):
                path = "scripts/1d.gdl"
            else:
                path = "scripts/3d.gdl"   # default: 3D
            collected[path] = block

    return collected


def check_gdl_script(content: str, script_type: str = "") -> list:
    """
    Basic GDL syntax check. Returns list of warning strings (empty = OK).
    Checks: IF/ENDIF, FOR/NEXT, ADD/DEL balance, END in 3D, PROJECT2 in 2D.
    """
    import re as _re
    issues = []
    if not content.strip():
        if script_type == "2d":
            issues.append("âš ï¸ 2D è„šæœ¬ä¸ºç©ºï¼Œå¿…é¡»è‡³å°‘åŒ…å« PROJECT2 3, 270, 2")
        return issues

    lines = content.splitlines()

    # IF/ENDIF balance (only multi-line IF: IF ... THEN at end of line)
    if_multi = sum(
        1 for l in lines
        if _re.search(r'\bIF\b', l, _re.I)
        and _re.search(r'\bTHEN\s*$', l.strip(), _re.I)
    )
    endif_count = sum(1 for l in lines if _re.match(r'\s*ENDIF\b', l, _re.I))
    if if_multi != endif_count:
        issues.append(f"âš ï¸ IF/ENDIF ä¸åŒ¹é…ï¼š{if_multi} ä¸ªå¤šè¡Œ IFï¼Œ{endif_count} ä¸ª ENDIF")

    # FOR/NEXT balance
    for_count = sum(1 for l in lines if _re.match(r'\s*FOR\b', l, _re.I))
    next_count = sum(1 for l in lines if _re.match(r'\s*NEXT\b', l, _re.I))
    if for_count != next_count:
        issues.append(f"âš ï¸ FOR/NEXT ä¸åŒ¹é…ï¼š{for_count} ä¸ª FORï¼Œ{next_count} ä¸ª NEXT")

    # ADD/DEL balance â€” ADDX/ADDY/ADDZ are single-axis variants, count equally
    add_count = sum(1 for l in lines if _re.match(r'\s*ADD(X|Y|Z)?\b', l, _re.I))
    del_count = sum(1 for l in lines if _re.match(r'\s*DEL\b', l, _re.I))
    if add_count != del_count:
        issues.append(f"âš ï¸ ADD/DEL ä¸åŒ¹é…ï¼š{add_count} ä¸ª ADD/ADDX/ADDY/ADDZï¼Œ{del_count} ä¸ª DEL")

    # Markdown fence leak â€” common when AI generates code in chat
    if any(l.strip().startswith("```") for l in lines):
        issues.append("âš ï¸ è„šæœ¬å«æœ‰ ``` æ ‡è®° â€” AI æ ¼å¼åŒ–æ®‹ç•™ï¼Œè¯·åˆ é™¤æ‰€æœ‰åå¼•å·è¡Œ")

    # 3D: END / subroutine RETURN check
    if script_type == "3d":
        # Detect subroutine labels:  "SubName":
        sub_label_pat = _re.compile(r'^\s*"[^"]+"\s*:')
        has_subs = any(sub_label_pat.match(l) for l in lines)

        if has_subs:
            # Main body = lines before first subroutine label
            main_body = []
            for l in lines:
                if sub_label_pat.match(l):
                    break
                main_body.append(l)
            last_main = next((l.strip() for l in reversed(main_body) if l.strip()), "")
            if not _re.match(r'^END\s*$', last_main, _re.I):
                issues.append("âš ï¸ 3D ä¸»ä½“éƒ¨åˆ†ï¼ˆç¬¬ä¸€ä¸ªå­ç¨‹åºä¹‹å‰ï¼‰æœ€åä¸€è¡Œå¿…é¡»æ˜¯ END")

            # Each subroutine should end with RETURN (not END)
            current_sub = None
            sub_lines: list[str] = []
            for l in lines:
                if sub_label_pat.match(l):
                    if current_sub and sub_lines:
                        last_sub = next((s.strip() for s in reversed(sub_lines) if s.strip()), "")
                        if not _re.match(r'^RETURN\s*$', last_sub, _re.I):
                            issues.append(f"âš ï¸ å­ç¨‹åº {current_sub} æœ«å°¾åº”ä¸º RETURNï¼Œä¸æ˜¯ END")
                    current_sub = l.strip()
                    sub_lines = []
                else:
                    sub_lines.append(l)
            # Check last subroutine
            if current_sub and sub_lines:
                last_sub = next((s.strip() for s in reversed(sub_lines) if s.strip()), "")
                if not _re.match(r'^RETURN\s*$', last_sub, _re.I):
                    issues.append(f"âš ï¸ å­ç¨‹åº {current_sub} æœ«å°¾åº”ä¸º RETURN")
        else:
            last_non_empty = next((l.strip() for l in reversed(lines) if l.strip()), "")
            if not _re.match(r'^END\s*$', last_non_empty, _re.I):
                issues.append("âš ï¸ 3D è„šæœ¬æœ€åä¸€è¡Œå¿…é¡»æ˜¯ END")

    # 2D: must have projection
    if script_type == "2d":
        has_proj = any(
            _re.search(r'\bPROJECT2\b|\bRECT2\b|\bPOLY2\b', l, _re.I)
            for l in lines
        )
        if not has_proj:
            issues.append("âš ï¸ 2D è„šæœ¬ç¼ºå°‘å¹³é¢æŠ•å½±è¯­å¥ï¼ˆPROJECT2 / RECT2ï¼‰")

    # _var æœªåœ¨æœ¬è„šæœ¬å†…èµ‹å€¼çš„ä¸­é—´å˜é‡ï¼ˆå¯èƒ½éœ€åœ¨ Master è„šæœ¬ä¸­å®šä¹‰ï¼‰
    assigned = set(_re.findall(r'\b(_[A-Za-z]\w*)\s*=', content))
    used     = set(_re.findall(r'\b(_[A-Za-z]\w*)\b', content))
    undefined = used - assigned
    if undefined:
        issues.append(
            f"â„¹ï¸ å˜é‡ {', '.join(sorted(undefined))} åœ¨æœ¬è„šæœ¬æœªèµ‹å€¼ â€” "
            "è‹¥å·²åœ¨ Master è„šæœ¬ä¸­å®šä¹‰å¯å¿½ç•¥ï¼Œå¦åˆ™ä¼šå¯¼è‡´ ArchiCAD è¿è¡Œæ—¶ä¸æ˜¾ç¤º"
        )

    if not issues:
        issues = ["âœ… æ£€æŸ¥é€šè¿‡"]
    return issues


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Main Layout: Left Chat | Right Editor
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

col_chat, col_editor = st.columns([2, 3], gap="large")


# â”€â”€ Left: Chat History â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with col_chat:
    if not st.session_state.project:
        st.markdown("### ğŸ’¬ å¼€å§‹åˆ›å»º")
        st.markdown(
            '<p style="color:#64748b; font-size:0.9rem;">åœ¨åº•éƒ¨è¾“å…¥æ¡†æè¿°ä½ æƒ³åˆ›å»ºçš„å¯¹è±¡ï¼ŒAI ä¼šè‡ªåŠ¨ç”Ÿæˆå¹¶ç¼–è¯‘ã€‚</p>',
            unsafe_allow_html=True,
        )
    else:
        proj_now = st.session_state.project
        st.markdown(f"### ğŸ’¬ {proj_now.name}")
        st.caption(f"å‚æ•°: {len(proj_now.parameters)} | è„šæœ¬: {len(proj_now.scripts)}")

    # Chat history
    for msg in st.session_state.chat_history:
        st.chat_message(msg["role"]).markdown(msg["content"])

    # Placeholder for live agent output (populated when agent runs)
    live_output = st.empty()


# â”€â”€ Right: Editor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _diff_summary(old: str, new: str) -> str:
    """Return a short +N/-N line diff summary."""
    old_lines = set(old.splitlines())
    new_lines = set(new.splitlines())
    added   = len(new_lines - old_lines)
    removed = len(old_lines - new_lines)
    return f"+{added} / -{removed} lines"


with col_editor:
    if not st.session_state.project:
        show_welcome()
    else:
        proj_now = st.session_state.project

        # â”€â”€ Toolbar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        tb_imp, tb_gsm_imp, tb_extract, tb_clear, tb_name, tb_compile, tb_check = st.columns(
            [1.0, 1.3, 1.0, 0.85, 1.8, 1.3, 1.1]
        )

        # ğŸ“‚ Import GDL (.gdl / .txt) â€” single script file
        with tb_imp:
            gdl_upload = st.file_uploader(
                "ğŸ“‚ GDL è„šæœ¬", type=["gdl", "txt"],
                key="toolbar_gdl_upload", help="å¯¼å…¥å•ä¸ª .gdl è„šæœ¬æ–‡ä»¶ï¼ˆè§£æä¸ºå¯¹è±¡ï¼‰"
            )
            if gdl_upload:
                content = gdl_upload.read().decode("utf-8", errors="replace")
                name = Path(gdl_upload.name).stem
                try:
                    imported = parse_gdl_source(content, name)
                    imported.work_dir = Path(st.session_state.work_dir)
                    imported.root = imported.work_dir / imported.name
                    st.session_state.project = imported
                    st.session_state.pending_diffs = {}
                    st.session_state.pending_gsm_name = imported.name
                    st.session_state.chat_history.append({
                        "role": "assistant",
                        "content": f"âœ… å·²å¯¼å…¥ GDL `{imported.name}` â€” {len(imported.parameters)} å‚æ•°ï¼Œ{len(imported.scripts)} è„šæœ¬",
                    })
                    st.rerun()
                except Exception as e:
                    st.error(f"å¯¼å…¥å¤±è´¥: {e}")

        # ğŸ“¦ Import GSM â€” full object package (LP mode only)
        with tb_gsm_imp:
            if compiler_mode.startswith("LP"):
                gsm_upload = st.file_uploader(
                    "ğŸ“¦ GSM å¯¹è±¡", type=["gsm"],
                    key="toolbar_gsm_upload", help="å¯¼å…¥ ArchiCAD .gsm å¯¹è±¡åŒ…ï¼Œéœ€ LP_XMLConverter"
                )
                if gsm_upload:
                    with st.spinner("è§£åŒ… GSM..."):
                        proj_imp, imp_msg = import_gsm(gsm_upload.read(), gsm_upload.name)
                    if proj_imp:
                        st.session_state.project = proj_imp
                        st.session_state.pending_diffs = {}
                        st.session_state.pending_gsm_name = proj_imp.name
                        st.session_state.chat_history.append({"role": "assistant", "content": imp_msg})
                        st.rerun()
                    else:
                        st.error(imp_msg)
            else:
                st.caption("GSM å¯¼å…¥\néœ€ LP æ¨¡å¼")

        # ğŸ“¥ Extract GDL code blocks from chat history â†’ apply directly
        with tb_extract:
            n_chat_blocks = sum(
                1 for m in st.session_state.chat_history
                if m.get("role") == "assistant" and "```" in m.get("content", "")
            )
            btn_label = f"ğŸ“¥ æå–({n_chat_blocks})" if n_chat_blocks else "ğŸ“¥ æå–"
            if st.button(btn_label, use_container_width=True,
                         help="ä»å¯¹è¯è®°å½•ä¸­æå– GDL ä»£ç å—ï¼Œç›´æ¥å†™å…¥å¯¹åº”è„šæœ¬"):
                extracted = _extract_gdl_from_chat()
                if extracted:
                    _apply_scripts_to_project(proj_now, extracted)
                    st.toast(f"ğŸ“¥ å·²å†™å…¥ {len(extracted)} ä¸ªè„šæœ¬", icon="âœ…")
                    st.rerun()
                else:
                    st.toast("å¯¹è¯ä¸­æœªå‘ç° GDL ä»£ç å—", icon="â„¹ï¸")

        # ğŸ—‘ï¸ Clear all scripts
        with tb_clear:
            if st.button("ğŸ—‘ï¸ æ¸…ç©º", use_container_width=True,
                         help="æ¸…ç©ºæ‰€æœ‰è„šæœ¬ä»£ç ï¼Œç­‰å¾…é‡æ–°å¯¼å…¥æˆ– AI ç”Ÿæˆ"):
                st.session_state.confirm_clear = True

        # GSM output name
        with tb_name:
            gsm_name_input = st.text_input(
                "è¾“å‡ºåç§°", label_visibility="collapsed",
                value=st.session_state.pending_gsm_name or proj_now.name,
                placeholder="è¾“å‡º GSM åç§°",
                key="toolbar_gsm_name",
                help="ç¼–è¯‘è¾“å‡ºæ–‡ä»¶åï¼ˆä¸å«ç‰ˆæœ¬å·å’Œæ‰©å±•åï¼‰",
            )
            st.session_state.pending_gsm_name = gsm_name_input

        # Compile button
        with tb_compile:
            if st.button("ğŸ”§ ç¼–è¯‘", type="primary", use_container_width=True,
                         help="ç¼–è¯‘å½“å‰æ‰€æœ‰è„šæœ¬ä¸º .gsm å¯¹è±¡"):
                with st.spinner("ç¼–è¯‘ä¸­..."):
                    success, result_msg = do_compile(
                        proj_now,
                        gsm_name=gsm_name_input or proj_now.name,
                        instruction="(toolbar compile)",
                    )
                st.session_state.chat_history.append({"role": "assistant", "content": result_msg})
                if success:
                    st.toast("âœ… ç¼–è¯‘æˆåŠŸ", icon="ğŸ—ï¸")
                else:
                    st.error(result_msg)
                st.rerun()

        # Global syntax check
        with tb_check:
            if st.button("ğŸ” å…¨æ£€æŸ¥", use_container_width=True):
                all_ok = True
                for stype, fpath, label in _SCRIPT_MAP:
                    content = proj_now.get_script(stype)
                    if not content:
                        continue
                    skey = fpath.replace("scripts/", "").replace(".gdl", "")
                    for iss in check_gdl_script(content, skey):
                        if iss.startswith("âœ…"):
                            st.success(f"{label}: {iss}")
                        else:
                            st.warning(f"{label}: {iss}")
                            all_ok = False
                if all_ok:
                    st.success("âœ… æ‰€æœ‰è„šæœ¬è¯­æ³•æ­£å¸¸")

        # â”€â”€ æ¸…ç©ºç¡®è®¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if st.session_state.get("confirm_clear"):
            st.warning("âš ï¸ å°†æ¸…ç©ºæ‰€æœ‰è„šæœ¬ä»£ç ï¼Œæ­¤æ“ä½œä¸å¯æ’¤é”€ã€‚ç¡®è®¤ç»§ç»­ï¼Ÿ")
            cc1, cc2, _ = st.columns([1, 1, 4])
            with cc1:
                if st.button("âœ… ç¡®è®¤æ¸…ç©º", type="primary"):
                    for stype, _fp, _lb in _SCRIPT_MAP:
                        proj_now.set_script(stype, "")
                    st.session_state.confirm_clear = False
                    st.toast("ğŸ—‘ï¸ å·²æ¸…ç©ºæ‰€æœ‰è„šæœ¬", icon="âœ…")
                    st.rerun()
            with cc2:
                if st.button("âŒ å–æ¶ˆ"):
                    st.session_state.confirm_clear = False
                    st.rerun()

        st.divider()

        # â”€â”€ Tab strip â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        tab_labels = (
            ["å‚æ•°"]
            + [label for _, _fp, label in _SCRIPT_MAP]
            + ["ğŸ“‹ æ—¥å¿—"]
        )
        all_tabs = st.tabs(tab_labels)
        tab_params = all_tabs[0]
        script_tabs = all_tabs[1:-1]
        tab_log = all_tabs[-1]

        # â”€â”€ å‚æ•° Tab â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with tab_params:
            with st.expander("â„¹ï¸ å‚æ•°è¯´æ˜"):
                st.markdown(
                    "**å‚æ•°åˆ—è¡¨** â€” GDL å¯¹è±¡çš„å¯è°ƒå‚æ•°ï¼Œå¯¹åº” ArchiCAD å¯¹è±¡è®¾ç½®é¢æ¿ä¸­çš„è¾“å…¥é¡¹ã€‚\n\n"
                    "- **Type**ï¼šæ•°æ®ç±»å‹ã€‚`Length` å¸¦å•ä½æ¢ç®—ï¼Œ`Integer` æ•´æ•°ï¼Œ`Boolean` å¼€å…³ï¼Œ"
                    "`Material` æè´¨é€‰æ‹©å™¨ï¼Œ`String` æ–‡å­—\n"
                    "- **Name**ï¼šä»£ç ä¸­å¼•ç”¨çš„å˜é‡åï¼Œå»ºè®®è‹±æ–‡ camelCaseï¼ˆå¦‚ `iShelves`ã€`bHasBack`ï¼‰\n"
                    "- **Value**ï¼šé»˜è®¤å€¼ï¼Œç”¨æˆ·æœªä¿®æ”¹æ—¶ä½¿ç”¨\n"
                    "- **Fixed**ï¼šå‹¾é€‰åç”¨æˆ·æ— æ³•åœ¨ ArchiCAD ä¸­ä¿®æ”¹æ­¤å‚æ•°\n\n"
                    "å‚æ•°åœ¨ 3D / 2D / Master è„šæœ¬ä¸­ç›´æ¥ç”¨å˜é‡åå¼•ç”¨ï¼Œæ— éœ€å£°æ˜ã€‚"
                )

            param_data = [
                {"Type": p.type_tag, "Name": p.name, "Value": p.value,
                 "Description": p.description, "Fixed": "âœ“" if p.is_fixed else ""}
                for p in proj_now.parameters
            ]
            if param_data:
                st.dataframe(param_data, use_container_width=True, hide_index=True)
            else:
                st.caption("æš‚æ— å‚æ•°ï¼Œé€šè¿‡å¯¹è¯è®© AI æ·»åŠ ï¼Œæˆ–æ‰‹åŠ¨æ·»åŠ ã€‚")

            with st.expander("â• æ‰‹åŠ¨æ·»åŠ å‚æ•°"):
                pc1, pc2, pc3, pc4 = st.columns(4)
                with pc1:
                    p_type = st.selectbox("Type", [
                        "Length", "Integer", "Boolean", "RealNum", "Angle",
                        "String", "Material", "FillPattern", "LineType", "PenColor",
                    ])
                with pc2:
                    p_name = st.text_input("Name", value="bNewParam")
                with pc3:
                    p_value = st.text_input("Value", value="0")
                with pc4:
                    p_desc = st.text_input("Description")
                if st.button("æ·»åŠ å‚æ•°"):
                    try:
                        proj_now.add_parameter(GDLParameter(p_name, p_type, p_desc, p_value))
                        st.success(f"âœ… {p_type} {p_name}")
                        st.rerun()
                    except Exception as e:
                        st.error(str(e))

            if st.button("ğŸ” éªŒè¯å‚æ•°"):
                issues = validate_paramlist(proj_now.parameters)
                for i in issues:
                    st.warning(i)
                if not issues:
                    st.success("âœ… å‚æ•°éªŒè¯é€šè¿‡")

            with st.expander("paramlist.xml é¢„è§ˆ"):
                st.code(build_paramlist_xml(proj_now.parameters), language="xml")

        # â”€â”€ Script Tabs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _SCRIPT_HELP = {
            "scripts/3d.gdl": (
                "**3D è„šæœ¬** â€” ä¸‰ç»´å‡ ä½•ä½“å®šä¹‰ï¼ŒArchiCAD 3D çª—å£ä¸­æ˜¾ç¤ºçš„å®ä½“ã€‚\n\n"
                "- ä½¿ç”¨ `PRISM_`ã€`BLOCK`ã€`SPHERE`ã€`CONE`ã€`REVOLVE` ç­‰å‘½ä»¤å»ºæ¨¡\n"
                "- `ADD` / `DEL` ç®¡ç†åæ ‡ç³»å˜æ¢ï¼Œå¿…é¡»æˆå¯¹å‡ºç°\n"
                "- `FOR` / `NEXT` å¾ªç¯ç”¨äºé‡å¤æ„ä»¶ï¼ˆå¦‚æ ¼æ …ã€å±‚æ¿ï¼‰\n"
                "- **æœ€åä¸€è¡Œå¿…é¡»æ˜¯ `END`**ï¼Œå¦åˆ™ç¼–è¯‘å¤±è´¥\n"
                "- å‚æ•°é€šè¿‡å˜é‡åç›´æ¥å¼•ç”¨ï¼ˆå¦‚ `A`ã€`B`ã€`iShelves`ï¼‰"
            ),
            "scripts/2d.gdl": (
                "**2D è„šæœ¬** â€” å¹³é¢å›¾ç¬¦å·ï¼ŒArchiCAD æ¥¼å±‚å¹³é¢å›¾ä¸­æ˜¾ç¤ºçš„çº¿æ¡ã€‚\n\n"
                "- **å¿…é¡»åŒ…å«** `PROJECT2 3, 270, 2`ï¼ˆæœ€ç®€æŠ•å½±ï¼‰æˆ–è‡ªå®šä¹‰ 2D çº¿æ¡\n"
                "- `PROJECT2` è‡ªåŠ¨å°† 3D å‡ ä½•æŠ•å½±ä¸ºå¹³é¢ï¼Œé€‚åˆå¤§å¤šæ•°å¯¹è±¡\n"
                "- å¤æ‚å¹³é¢ç¬¦å·å¯ç”¨ `LINE2`ã€`ARC2`ã€`POLY2`ã€`RECT2` æ‰‹ç»˜\n"
                "- ä¸å†™æˆ–ç•™ç©ºä¼šå¯¼è‡´å¹³é¢å›¾ä¸­å¯¹è±¡ä¸å¯è§"
            ),
            "scripts/1d.gdl": (
                "**Master è„šæœ¬** â€” ä¸»æ§è„šæœ¬ï¼Œæ‰€æœ‰è„šæœ¬æ‰§è¡Œå‰æœ€å…ˆè¿è¡Œã€‚\n\n"
                "- ç”¨äºå…¨å±€å˜é‡åˆå§‹åŒ–ã€å‚æ•°è”åŠ¨é€»è¾‘ã€æ¡ä»¶åˆ¤æ–­\n"
                "- å¯å¼•ç”¨ `GLOB_` ç³»åˆ—å…¨å±€å˜é‡ï¼ˆå¦‚ `GLOB_SCALE`ã€`GLOB_NORTH`ï¼‰\n"
                "- ä¸ç›´æ¥äº§ç”Ÿå‡ ä½•ï¼Œåªåšæ•°æ®å¤„ç†\n"
                "- ç®€å•å¯¹è±¡é€šå¸¸ä¸éœ€è¦æ­¤è„šæœ¬"
            ),
            "scripts/vl.gdl": (
                "**Param è„šæœ¬** â€” å‚æ•°éªŒè¯è„šæœ¬ï¼Œå‚æ•°å€¼å‘ç”Ÿå˜åŒ–æ—¶è§¦å‘ã€‚\n\n"
                "- ç”¨äºå‚æ•°èŒƒå›´çº¦æŸï¼ˆå¦‚å®½åº¦ä¸èƒ½å°äº 0ï¼‰\n"
                "- æ´¾ç”Ÿå‚æ•°è®¡ç®—ï¼ˆå¦‚æ ¹æ®å®½åº¦è‡ªåŠ¨è®¡ç®—æ ¼æ …é—´è·ï¼‰\n"
                "- `LOCK` è¯­å¥å¯é”å®šå‚æ•°é˜²æ­¢ç”¨æˆ·ä¿®æ”¹\n"
                "- ç®€å•å¯¹è±¡é€šå¸¸ä¸éœ€è¦æ­¤è„šæœ¬"
            ),
            "scripts/ui.gdl": (
                "**UI è„šæœ¬** â€” è‡ªå®šä¹‰å‚æ•°ç•Œé¢ï¼ŒArchiCAD å¯¹è±¡è®¾ç½®å¯¹è¯æ¡†ä¸­çš„æ§ä»¶å¸ƒå±€ã€‚\n\n"
                "- ä½¿ç”¨ `UI_INFIELD`ã€`UI_BUTTON`ã€`UI_SEPARATOR` ç­‰å‘½ä»¤\n"
                "- ä¸å†™åˆ™ ArchiCAD è‡ªåŠ¨ç”Ÿæˆé»˜è®¤å‚æ•°åˆ—è¡¨ç•Œé¢\n"
                "- ç”¨äºéœ€è¦ç²¾ç»†åŒ–ç”¨æˆ·ä½“éªŒçš„å•†ä¸šæ„ä»¶\n"
                "- å¯¹ä¸€èˆ¬è‡ªç”¨æ„ä»¶å¯ç•™ç©º"
            ),
            "scripts/pr.gdl": (
                "**Properties è„šæœ¬** â€” BIM å±æ€§è¾“å‡ºï¼Œå®šä¹‰ IFC å±æ€§é›†å’Œæ„ä»¶å±æ€§ã€‚\n\n"
                "- ç”¨äºè¾“å‡º IFC åˆè§„æ•°æ®ï¼ˆå¦‚æˆ¿é—´é¢ç§¯ã€æè´¨è§„æ ¼ï¼‰\n"
                "- `PROPERTY` è¯­å¥å®šä¹‰å±æ€§åå’Œå€¼\n"
                "- ä¸æ¨¡å‹ç®—é‡ã€èƒ½è€—åˆ†æã€æ–½å·¥é¢„ç®—ç›´æ¥æŒ‚é’©\n"
                "- ä¸åš BIM æ•°æ®è¾“å‡ºå¯ç•™ç©º"
            ),
        }

        for tab, (stype, fpath, label) in zip(script_tabs, _SCRIPT_MAP):
            with tab:
                # Help expander â€” collapsed by default
                with st.expander(f"â„¹ï¸ {label} è„šæœ¬è¯´æ˜"):
                    st.markdown(_SCRIPT_HELP.get(fpath, ""))

                current_code = proj_now.get_script(stype) or ""
                skey = fpath.replace("scripts/", "").replace(".gdl", "")

                # â”€â”€ Single editor (AI writes directly, no diff confirm needed) â”€â”€
                new_code = st.text_area(
                    label, value=current_code, height=400,
                    key=f"script_{fpath}", label_visibility="collapsed",
                )
                if new_code != current_code:
                    proj_now.set_script(stype, new_code)

                if st.button(f"ğŸ” æ£€æŸ¥", key=f"chk_{fpath}"):
                    for iss in check_gdl_script(new_code, skey):
                        if iss.startswith("âœ…"):
                            st.success(iss)
                        else:
                            st.warning(iss)

        # â”€â”€ æ—¥å¿— Tab â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with tab_log:
            if not st.session_state.compile_log:
                st.info("æš‚æ— ç¼–è¯‘è®°å½•")
            else:
                for entry in reversed(st.session_state.compile_log):
                    icon = "âœ…" if entry["success"] else "âŒ"
                    st.markdown(f"**{icon} {entry['project']}** â€” {entry.get('instruction','')}")
                    st.code(entry["message"], language="text")
                    st.divider()
            if st.button("æ¸…é™¤æ—¥å¿—"):
                st.session_state.compile_log = []
                st.rerun()

            with st.expander("HSF ç›®å½•ç»“æ„"):
                tree = [f"ğŸ“ {proj_now.name}/", "  â”œâ”€â”€ libpartdata.xml",
                        "  â”œâ”€â”€ paramlist.xml", "  â”œâ”€â”€ ancestry.xml", "  â””â”€â”€ scripts/"]
                for stype in ScriptType:
                    if stype in proj_now.scripts:
                        n = proj_now.scripts[stype].count("\n") + 1
                        tree.append(f"       â”œâ”€â”€ {stype.value} ({n} lines)")
                st.code("\n".join(tree), language="text")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Chat Input â€” Always at Bottom
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

user_input = st.chat_input(
    "æè¿°ä½ æƒ³åˆ›å»ºæˆ–ä¿®æ”¹çš„ GDL å¯¹è±¡ï¼Œå¦‚ã€Œåˆ›å»ºä¸€ä¸ªå®½ 600mm çš„ä¹¦æ¶ï¼ŒiShelves æ§åˆ¶å±‚æ•°ã€"
)

if user_input:
    # Add user message to history
    st.session_state.chat_history.append({"role": "user", "content": user_input})

    # Check API key first
    if not api_key and "ollama" not in model_name:
        err = "âŒ è¯·åœ¨å·¦ä¾§è¾¹æ å¡«å…¥ API Key åå†è¯•ã€‚"
        st.session_state.chat_history.append({"role": "assistant", "content": err})
        st.rerun()
    else:
        llm_for_classify = get_llm()

        # â”€â”€ Intent + Name in ONE call â”€â”€
        intent, gdl_obj_name = classify_and_extract(
            user_input, llm_for_classify,
            project_loaded=bool(st.session_state.project),
        )

        with live_output.container():
            st.chat_message("user").markdown(user_input)
            with st.chat_message("assistant"):
                if intent == "CHAT":
                    # â”€â”€ Casual conversation â€” no project creation, no agent â”€â”€
                    msg = chat_respond(
                        user_input,
                        st.session_state.chat_history[:-1],
                        llm_for_classify,
                    )
                    st.markdown(msg)

                else:
                    # â”€â”€ GDL intent â€” create project if needed, then run agent â”€â”€
                    if not st.session_state.project:
                        new_proj = HSFProject.create_new(gdl_obj_name, work_dir=st.session_state.work_dir)
                        st.session_state.project = new_proj
                        st.session_state.pending_gsm_name = gdl_obj_name
                        st.info(f"ğŸ“ å·²åˆå§‹åŒ–é¡¹ç›® `{gdl_obj_name}`")

                    proj_current = st.session_state.project
                    # Keep existing gsm_name if project already loaded
                    effective_gsm = (
                        st.session_state.pending_gsm_name
                        or proj_current.name
                    )
                    msg = run_agent_generate(user_input, proj_current, st.container(), gsm_name=effective_gsm)
                    st.markdown(msg)

        st.session_state.chat_history.append({"role": "assistant", "content": msg})
        st.rerun()


# â”€â”€ Footer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.divider()
st.markdown(
    '<p style="text-align:center; color:#64748b; font-size:0.8rem;">'
    'gdl-agent v0.5.0 Â· HSF-native Â·'
    '<a href="https://github.com/byewind/gdl-agent">GitHub</a>'
    '</p>',
    unsafe_allow_html=True,
)
